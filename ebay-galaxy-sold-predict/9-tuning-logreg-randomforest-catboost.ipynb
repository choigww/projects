{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specified-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn. neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.stats import expon, reciprocal\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from missingpy import MissForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            #print(\"******************************\")\n",
    "            #print(\"Column: \",col)\n",
    "            #print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            #print(\"dtype after: \",props[col].dtype)\n",
    "            #print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faced-vertical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1485 entries, 0 to 1484\n",
      "Data columns (total 14 columns):\n",
      "index                        1485 non-null int64\n",
      "BuyItNow                     1485 non-null int64\n",
      "startprice                   1485 non-null float64\n",
      "productSeries_imputed        1485 non-null int64\n",
      "product_isNote_imputed       1485 non-null int64\n",
      "hasDescription               1485 non-null int64\n",
      "charCountDescriptionBins     1485 non-null int64\n",
      "upperCaseDescription_rate    1485 non-null float64\n",
      "startprice_point9            1485 non-null int64\n",
      "sold                         1485 non-null int64\n",
      "color_sentiment_0            1485 non-null int64\n",
      "color_sentiment_1            1485 non-null int64\n",
      "carrier_none_0               1485 non-null int64\n",
      "carrier_none_1               1485 non-null int64\n",
      "dtypes: float64(2), int64(12)\n",
      "memory usage: 174.0 KB\n",
      "Memory usage of properties dataframe is : 0.16994476318359375  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  0.041069984436035156  MB\n",
      "This is  24.166666666666668 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/galaxy_final.csv', index_col=0)\n",
    "df.info()\n",
    "df, na_li = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medical-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sold', axis=1)\n",
    "y = df.sold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11,\n",
    "                                                       stratify=y, shuffle=True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=11,\n",
    "                                                       stratify=y_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-somalia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "controlling-architecture",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "undefined-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 51840 candidates, totalling 259200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2380 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 6380 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 11980 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 19180 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 27980 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 38380 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 50380 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 63980 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 79180 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 95980 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 104900 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 109900 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 115604 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 127204 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 139604 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 152804 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 166804 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 181604 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 197204 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done 213604 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 230804 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=-1)]: Done 248804 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 259200 out of 259200 | elapsed: 32.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=0.1, max_iter=25,\n",
      "                   multi_class='ovr', n_jobs=-1, penalty='l1',\n",
      "                   random_state=None, solver='liblinear', tol=1, verbose=0,\n",
      "                   warm_start=False), 'classifier__C': 100.0, 'classifier__fit_intercept': True, 'classifier__intercept_scaling': 1, 'classifier__l1_ratio': 0.1, 'classifier__max_iter': 25, 'classifier__multi_class': 'ovr', 'classifier__n_jobs': -1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'classifier__tol': 1, 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "0.7789473684210526\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(LGBMClassifier())),\n",
    "                ('classifier', LogisticRegression())\n",
    "                ])\n",
    "\n",
    "param_grid1 = [              \n",
    "              {'classifier': [LogisticRegression()],\n",
    "               'classifier__penalty':['l1', 'l2'],\n",
    "               'classifier__tol':[1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100],\n",
    "               'classifier__C':[1e-2, 0.1, 0.0, 1.0, 1.0, 100.0],\n",
    "              'classifier__fit_intercept':[True],\n",
    "              'classifier__intercept_scaling':[0.01, 0.1, 1, 10],\n",
    "               'classifier__solver':['liblinear'],\n",
    "               'classifier__max_iter':[25, 50, 100, 150, 200],\n",
    "               'classifier__multi_class':['ovr'],\n",
    "              'classifier__l1_ratio': [0.1*i for i in range(1, 10)],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#               'feature_selection' : [RFE(LGBMClassifier(objective='binary',\n",
    "#                                                         metric='binary_logloss'))],\n",
    "#                 'feature_selection__n_features_to_select' : [140, 70, 35]\n",
    "              }\n",
    "             ]\n",
    "grid1 = GridSearchCV(pipe, param_grid1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1.fit(X_train, y_train)\n",
    "print(grid1.best_params_)\n",
    "print(grid1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-moisture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-musician",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "purple-diameter",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "- https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/\n",
    "- https://www.upgrad.com/blog/random-forest-hyperparameter-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(XGBClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree': [3],\n",
    "               'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "               'feature_selection__n_features_to_select' : [140, 70]\n",
    "              }\n",
    "             ]\n",
    "grid1 = GridSearchCV(pipe1, param_grid1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1.fit(X_valid, y_valid)\n",
    "print(grid1.best_params_)\n",
    "print(grid1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-integer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "            'bootstrap': [True, False],\n",
    "            'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100, cv = 3,\n",
    "                               verbose=2, random_state=2021, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-motivation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-direction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':[50, 100, 150],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth':[6, 8, 10, 12],\n",
    "    'min_samples_leaf':[8, 12, 18],\n",
    "    'min_samples_split':[8, 16, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(LGBMClassifier())),\n",
    "                ('classifier', LGBMClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1 = [              \n",
    "              {'classifier': [LGBMClassifier()],\n",
    "               'classifier__categorical_feature':[cat_features_idx],\n",
    "               'classifier__objective':['binary'],\n",
    "               'classifier__metric':['binary_logloss'],\n",
    "              'classifier__boosting_type':['gbdt', 'dart'],\n",
    "              'classifier__drop_rate':[0.1],\n",
    "               'classifier__skip_drop':[0.5],\n",
    "               'classifier__learning_rate':[0.01, 0.03, 0.1],\n",
    "               'classifier__num_iterations':[500, 1000, 2000, 3000, 5000],\n",
    "              'classifier__bagging_fraction': [0.8],\n",
    "               'classifier__feature_fraction':[0.8],\n",
    "               'classifier__early_stopping_round':[0],\n",
    "               'classifier__max_depth': [5],\n",
    "               'classifier__num_leaves':[2**3],\n",
    "               'classifier__min_data_in_leaf':[20],\n",
    "               'classifier__max_bin':[255],\n",
    "               'classifier__n_estimators':[1000],\n",
    "               'classifier__lambda_l1':[0],\n",
    "               'classifier__lambda_l2':[0],\n",
    "               'classifier__scale_pos_weight':[1.0],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#               'feature_selection' : [RFE(LGBMClassifier(objective='binary',\n",
    "#                                                         metric='binary_logloss'))],\n",
    "#                 'feature_selection__n_features_to_select' : [140, 70, 35]\n",
    "              }\n",
    "             ]\n",
    "grid1 = GridSearchCV(pipe, param_grid1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1.fit(X_train, y_train)\n",
    "print(grid1.best_params_)\n",
    "print(grid1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-easter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-sector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-blackberry",
   "metadata": {},
   "source": [
    "# Catboost vs. LGBM vs. XGBOOST\n",
    "https://www.kdnuggets.com/2018/03/catboost-vs-light-gbm-vs-xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-guidance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-kitchen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-development",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-remainder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-invitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-interface",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-tradition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
