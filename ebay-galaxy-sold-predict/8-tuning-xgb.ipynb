{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "future-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn. neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.stats import expon, reciprocal\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from missingpy import MissForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "searching-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/galaxy_final.csv', index_col=0)\n",
    "X = df.drop('sold', axis=1)\n",
    "y = df.sold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11,\n",
    "                                                       stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "respected-program",
   "metadata": {},
   "source": [
    "# XGBoost Tuning\n",
    "- https://www.kaggle.com/lifesailor/xgboost\n",
    "- https://brunch.co.kr/@snobberys/137\n",
    "- https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "\n",
    "General Parameter\n",
    "- booster: tree 기반 모델 / 선형 모델\n",
    "    - https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "    - skip_drop(default = 0, range [0, 1]) is the probability of skipping dropout. It has a higher priority than other DART parameters.\n",
    "        - If skip_drop = 1, the dropout procedure would be skipped and dart is the same as gbtree.\n",
    "    - If skip_drop≠0, rate_drop (default = 0, range [0, 1]) will drop a fraction of the trees before the model update in every iteration.\n",
    "        - dropout makes dart between gbtree and random forest: “If no tree is dropped, dart is the same as (gbtree); if all the trees are dropped, dart is no different than random forest.”\n",
    "- silent: 메세지 조절\n",
    "- nthread: 병렬 처리 조절\n",
    "\n",
    "Boost Parameter\n",
    "- eta: Learning rate(일반적으로 0.01 - 0.2)\n",
    "- min_child_weight: min_child_weight를 기준으로 추가 분기 결정(크면 Underfitting)\n",
    "- max_depth: Tree 깊이 수\n",
    "- max_leaf_node: 하나의 트리에서 node 개수\n",
    "- gamma: split 하기 위한 최소의 loss 감소 정의\n",
    "- subsample: 데이터 중 샘플링(0.5 - 1)\n",
    "- colsample_bytree: column 중 sampling(0.5 - 1)\n",
    "- colsample_bylevel: 각 level마다 샘플링 비율\n",
    "- lambda: L2 nrom\n",
    "- alpha: L1 norm\n",
    "- scale_pos_weight: positive, negative weight 지정\n",
    "- 기타 등\n",
    "\n",
    "Learning Task Parameter\n",
    "- object: 목적함수 종류\n",
    "    - binary:logistic(이진 분류)\n",
    "    - multi:softmax(다중 분류)\n",
    "    - multi-softprob(다중 확률)\n",
    "- eval_metric: 평가 지표\n",
    "    - rmse – root mean square error\n",
    "    - mae – mean absolute error\n",
    "    - logloss – negative log-likelihood\n",
    "    - error – Binary classification error rate (0.5 threshold)\n",
    "    - merror – Multiclass classification error rate\n",
    "    - mlogloss – Multiclass logloss\n",
    "    - auc: Area under the curve\n",
    "seed\n",
    "\n",
    "### Overview\n",
    "- high learning rate(0.05 - 0.3)를 선택하고 이 학습률에 맞는 tree 개수를 선정한다.\n",
    "- tree-specific parameter를 수정한다.\n",
    "- max_depth, min_child_weight, gamma, subsample, colsample_bytree\n",
    "- regularization parameter를 수정한다.\n",
    "- 학습률을 낮추고 다시 반복한다.\n",
    "\n",
    "### Initialization\n",
    "초기값은 다음과 같이 선정한다.\n",
    "- max_depth = 5: 보통 4-6 를 시작점으로 한다.\n",
    "- min_child_weight = 1 : 향후에 튜닝할 것이다.\n",
    "- gamma = 0 : 0.1 - 0.2로 시작해도 된다. 그런데 어짜피 튜닝할 것이다.\n",
    "- subsample, colsample_bytree = 0.8 : 보통 0.5 - 0.9로 시작한다.\n",
    "- scale_pos_weight = 1: Because of high class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-constraint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "protecting-sauce",
   "metadata": {},
   "source": [
    "### 1-1. Scaler + PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "yellow-vatican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8047193560968692\n"
     ]
    }
   ],
   "source": [
    "pipe1_1 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "             ] \n",
    "grid1_1 = GridSearchCV(pipe1_1, param_grid1_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_1.fit(X_train, y_train)\n",
    "print(grid1_1.best_params_)\n",
    "print(grid1_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-publication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mental-copyright",
   "metadata": {},
   "source": [
    "### 1-2. Scaler Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "micro-framing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'scale': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "0.7971492394426125\n"
     ]
    }
   ],
   "source": [
    "pipe1_2 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_2 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "             ] \n",
    "grid1_2 = GridSearchCV(pipe, param_grid1_2, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_2.fit(X_train, y_train)\n",
    "print(grid1_2.best_params_)\n",
    "print(grid1_2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-jason",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "swedish-bacon",
   "metadata": {},
   "source": [
    "### 1-3. Scale -> Poly -> ReduceDim\n",
    "\n",
    "- PCA & LDA\n",
    "    - https://huidea.tistory.com/126\n",
    "- LDA\n",
    "    - https://yamalab.tistory.com/41\n",
    "    - http://www.datamarket.kr/xe/board_oFxn34/26649\n",
    "- TSNE\n",
    "    - https://agiantmind.tistory.com/215\n",
    "    - https://lovit.github.io/nlp/representation/2018/09/28/tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "asian-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 64.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=1, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 1, 'reduce_dims': PCA(copy=True, iterated_power='auto', n_components=9, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'reduce_dims__n_components': 9, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.7887281494876431\n"
     ]
    }
   ],
   "source": [
    "pipe1_3 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()),\n",
    "                ('reduce_dims', PCA()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_3 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree': [1, 2, 3],\n",
    "               'reduce_dims' : [PCA(), LDA(), TSNE()],\n",
    "               'reduce_dims__n_components' : [5, 7, 9, 11]\n",
    "              }\n",
    "             ] \n",
    "grid1_3 = GridSearchCV(pipe1_3, param_grid1_3, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_3.fit(X_train, y_train)\n",
    "print(grid1_3.best_params_)\n",
    "print(grid1_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sharing-liberty",
   "metadata": {},
   "source": [
    "### 1-4. Scale -> Poly -> Feature Selection\n",
    "\n",
    "```python\n",
    "len(PolynomialFeatures(3).fit_transform(X_train)[0, :]) = 560\n",
    "```\n",
    "- 280\n",
    "- 140\n",
    "- 70\n",
    "- 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "centered-shield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 162.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'feature_selection': RFE(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                     class_weight=None, criterion='gini',\n",
      "                                     max_depth=None, max_features='auto',\n",
      "                                     max_leaf_nodes=None, max_samples=None,\n",
      "                                     min_impurity_decrease=0.0,\n",
      "                                     min_impurity_split=None,\n",
      "                                     min_samples_leaf=1, min_samples_split=2,\n",
      "                                     min_weight_fraction_leaf=0.0,\n",
      "                                     n_estimators=100, n_jobs=None,\n",
      "                                     oob_score=False, random_state=None,\n",
      "                                     verbose=0, warm_start=False),\n",
      "    n_features_to_select=140, step=1, verbose=0), 'feature_selection__n_features_to_select': 140, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "0.8080913378009431\n"
     ]
    }
   ],
   "source": [
    "pipe1_4 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(LogisticRegression())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_4 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree': [1, 2, 3],\n",
    "               'feature_selection' : [RFE(LogisticRegression()),\n",
    "                                     RFE(RandomForestClassifier())],\n",
    "               'feature_selection__n_features_to_select' : [280, 140, 70, 35]\n",
    "#                'reduce_dims' : [PCA(), LDA(), TSNE()],\n",
    "#                'reduce_dims__n_components' : [5, 7, 9, 11]\n",
    "              }\n",
    "             ]\n",
    "grid1_4 = GridSearchCV(pipe1_4, param_grid1_4, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_4.fit(X_train, y_train)\n",
    "print(grid1_4.best_params_)\n",
    "print(grid1_4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-shoot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "foster-drill",
   "metadata": {},
   "source": [
    "### Scaler+RFE+Scaler + Poly > Scaler Only > Scaler + Poly + DimReduction\n",
    "- 0.808 > 0.805 > 0.797 > 0.789\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-following",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "international-marker",
   "metadata": {},
   "source": [
    "### max_depth, min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entire-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8106229833705635\n"
     ]
    }
   ],
   "source": [
    "# grid1_3 base (scaler-poly-xgb)\n",
    "# max_depth와 min_child_weight를 튜닝한다.\n",
    "\n",
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid2 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':range(3,10,3),\n",
    "               'classifier__min_child_weight':range(1,6,2),\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid2 = GridSearchCV(pipe, param_grid2, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid2.fit(X_train, y_train)\n",
    "print(grid2.best_params_)\n",
    "print(grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "operating-telephone",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-da6e16daba52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     verbose=1, n_jobs=-1)\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mgrid2_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid2_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid2_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# max_depth와 min_child_weight를 튜닝한다.\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid2_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':range(3,10,3),\n",
    "               'classifier__min_child_weight':range(1,6,2),\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3],\n",
    "               'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "               'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid2_1 = GridSearchCV(pipe_1_4, param_grid2_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid2_1.fit(X_train, y_train)\n",
    "print(grid2_1.best_params_)\n",
    "print(grid2_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-ordering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-texture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "different-stream",
   "metadata": {},
   "source": [
    "### Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cross-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8106229833705635\n"
     ]
    }
   ],
   "source": [
    "# grid1_3 base (scaler-poly-xgb)\n",
    "# Gamma를 튜닝한다.\n",
    "param_grid3 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[i/10.0 for i in range(0,10)],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid3 = GridSearchCV(pipe, param_grid3, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid3.fit(X_train, y_train)\n",
    "print(grid3.best_params_)\n",
    "print(grid3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# Gamma 튜닝\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid3_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2_1.best_params_['classifier__max_depth']], # \n",
    "               'classifier__min_child_weight': [grid2_1.best_params_['classifier__min_child_weight']], \n",
    "               'classifier__gamma':[i/10.0 for i in range(0,10)],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3],\n",
    "               'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "               'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid3_1 = GridSearchCV(pipe_1_4, param_grid3_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid3_1.fit(X_train, y_train)\n",
    "print(grid3_1.best_params_)\n",
    "print(grid3_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "practical-diary",
   "metadata": {},
   "source": [
    "### subsample, colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rising-animation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8156791830656314\n"
     ]
    }
   ],
   "source": [
    "# subsample and colsample_bytree를 튜닝한다.\n",
    "param_grid4 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid4 = GridSearchCV(pipe, param_grid4, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid4.fit(X_train, y_train)\n",
    "print(grid4.best_params_)\n",
    "print(grid4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-privacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-retirement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "violent-words",
   "metadata": {},
   "source": [
    "### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "african-spencer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8156791830656314\n"
     ]
    }
   ],
   "source": [
    "# n_estimators 튜닝\n",
    "\n",
    "param_grid5 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[50, 100, 300, 500, 750, 1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid5 = GridSearchCV(pipe, param_grid5, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid5.fit(X_train, y_train)\n",
    "print(grid5.best_params_)\n",
    "print(grid5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-jesus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "express-negative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 96.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.3500000000000001, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
      "              skip_drop=0.30000000000000004, subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.3500000000000001, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.30000000000000004, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8165124277559125\n"
     ]
    }
   ],
   "source": [
    "# rate_drop, skip_drop 튜닝\n",
    "param_grid6 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': np.arange(0.1, 0.55, 0.05),\n",
    "              'classifier__skip_drop': np.arange(0.1, 0.55, 0.05),\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[grid5.best_params_['classifier__n_estimators']], # 1000\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid6 = GridSearchCV(pipe, param_grid6, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid6.fit(X_train, y_train)\n",
    "print(grid6.best_params_)\n",
    "print(grid6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-insured",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "equipped-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.3500000000000001, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
      "              skip_drop=0.30000000000000004, subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.3500000000000001, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.30000000000000004, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8165124277559125\n"
     ]
    }
   ],
   "source": [
    "# learning rate\n",
    "\n",
    "param_grid7 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [grid6.best_params_['classifier__rate_drop']],\n",
    "              'classifier__skip_drop': [grid6.best_params_['classifier__skip_drop']],\n",
    "             'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "             'classifier__n_estimators':[grid5.best_params_['classifier__n_estimators']], # 1000\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ]\n",
    "grid7 = GridSearchCV(pipe, param_grid7, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid7.fit(X_train, y_train)\n",
    "print(grid7.best_params_)\n",
    "print(grid7.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-resource",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-jordan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "strong-festival",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-075018fbdc6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX_test_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mX_train_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mX_valid_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mX_test_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         indices = _generate_sample_indices(tree.random_state, n_samples,\n\u001b[0;32m--> 154\u001b[0;31m                                            n_samples_bootstrap)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[0;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    117\u001b[0m     Private function used to _parallel_build_trees function.\"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mrandom_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0msample_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.BitGenerator.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.get_assembled_entropy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit - early stopping rounds\n",
    "#xgb_best = grid7.best_estimator_[2]\n",
    "xgb_best = XGBClassifier(booster='dart', colsample_bytree=0.9, eval_metric='error',\n",
    "              gamma=0.0, importance_type='gain', learning_rate=0.1,\n",
    "              max_depth=3, min_child_weight=1,\n",
    "              n_estimators=1000, n_jobs=-1,\n",
    "              nthread=-1, objective='binary:logistic',\n",
    "              rate_drop=0.3500000000000001, \n",
    "              scale_pos_weight=1, seed=2021,\n",
    "              skip_drop=0.30000000000000004, subsample=0.7)\n",
    "\n",
    "best_esr_stoprounds = (-1, -1)\n",
    "for i, esr in enumerate(np.arange(50, 550, 50)):\n",
    "    X_train_c, X_test_c, y_train_c, y_test_c = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "    X_train_c, X_valid_c, y_train_c, y_valid_c = train_test_split(X_train_c, y_train_c,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y_train_c,\n",
    "                                                                    random_state=11)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    \n",
    "    X_train_c = scaler.fit_transform(X_train_c)\n",
    "    X_valid_c = scaler.transform(X_valid_c)\n",
    "    X_test_c = scaler.transform(X_test_c)\n",
    "    \n",
    "    X_train_c = poly.fit_transform(X_train_c)\n",
    "    X_valid_c = poly.transform(X_valid_c)\n",
    "    X_test_c = poly.transform(X_test_c)\n",
    "    \n",
    "    xgb_best.fit(X_train_c, y_train_c, early_stopping_rounds=esr, eval_metric=\"error\",\n",
    "                 eval_set=[(X_train_c, y_train_c), (X_valid_c, y_valid_c)], verbose=0)\n",
    "    acc = accuracy_score(y_test, xgb_best.predict(X_test_c))\n",
    "    \n",
    "    if acc > best_esr_stoprounds[1]:\n",
    "        best_esr_stoprounds = (esr, acc)\n",
    "        print(i, best_esr_stoprounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "alert-politics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 0.8383838383838383)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_esr_stoprounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-angel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accessory-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (50, 0.8282828282828283)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cf3f44418e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mX_test_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mX_train_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mX_valid_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mX_test_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_best = XGBClassifier(booster='dart', colsample_bytree=0.9, eval_metric='error',\n",
    "              gamma=0.0, importance_type='gain', learning_rate=0.1,\n",
    "              max_depth=3, min_child_weight=1,\n",
    "              n_estimators=1000, n_jobs=-1,\n",
    "              nthread=-1, objective='binary:logistic',\n",
    "              rate_drop=0.3500000000000001, \n",
    "              scale_pos_weight=1, seed=2021,\n",
    "              skip_drop=0.30000000000000004, subsample=0.7)\n",
    "\n",
    "best_esr_stoprounds_rfe = (-1, -1)\n",
    "for i, esr in enumerate(np.arange(50, 550, 50)):\n",
    "    X_train_c, X_test_c, y_train_c, y_test_c = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "    X_train_c, X_valid_c, y_train_c, y_valid_c = train_test_split(X_train_c, y_train_c,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y_train_c,\n",
    "                                                                    random_state=11)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    rfe = RFE(RandomForestClassifier(), n_features_to_select=140)\n",
    "    \n",
    "    X_train_c = scaler.fit_transform(X_train_c)\n",
    "    X_valid_c = scaler.transform(X_valid_c)\n",
    "    X_test_c = scaler.transform(X_test_c)\n",
    "    \n",
    "    X_train_c = poly.fit_transform(X_train_c)\n",
    "    X_valid_c = poly.transform(X_valid_c)\n",
    "    X_test_c = poly.transform(X_test_c)\n",
    "    \n",
    "    X_train_c = rfe.fit_transform(X_train_c, y_train_c)\n",
    "    X_valid_c = rfe.transform(X_valid_c)\n",
    "    X_test_c = rfe.transform(X_test_c)\n",
    "    \n",
    "    xgb_best.fit(X_train_c, y_train_c, early_stopping_rounds=esr, eval_metric=\"error\",\n",
    "                 eval_set=[(X_train_c, y_train_c), (X_valid_c, y_valid_c)], verbose=0)\n",
    "    acc = accuracy_score(y_test, xgb_best.predict(X_test_c))\n",
    "    \n",
    "    if acc > best_esr_stoprounds_rfe[1]:\n",
    "        best_esr_stoprounds_rfe = (esr, acc)\n",
    "        print(i, best_esr_stoprounds_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_esr_stoprounds_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-approval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "delayed-volume",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "previous-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "X_train_c = scaler.fit_transform(X_train_c)\n",
    "X_test_c = scaler.transform(X_test_c)\n",
    "X_train_p = poly.fit_transform(X_train_c)\n",
    "X_test_p = poly.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "hidden-savannah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 560)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_c[0, :]), len(X_train_p[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demanding-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>startprice</td>\n",
       "      <td>0.039908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>productSeries_imputed</td>\n",
       "      <td>0.016792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BuyItNow</td>\n",
       "      <td>0.007788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             features_name  importance\n",
       "2               startprice    0.039908\n",
       "27                     NaN    0.026178\n",
       "196                    NaN    0.020621\n",
       "16                     NaN    0.019841\n",
       "3    productSeries_imputed    0.016792\n",
       "38                     NaN    0.015045\n",
       "207                    NaN    0.013881\n",
       "29                     NaN    0.013553\n",
       "107                    NaN    0.012192\n",
       "118                    NaN    0.011159\n",
       "274                    NaN    0.011039\n",
       "39                     NaN    0.010202\n",
       "273                    NaN    0.010083\n",
       "130                    NaN    0.009622\n",
       "105                    NaN    0.009202\n",
       "106                    NaN    0.009051\n",
       "119                    NaN    0.008993\n",
       "275                    NaN    0.008923\n",
       "14                     NaN    0.008737\n",
       "131                    NaN    0.008241\n",
       "28                     NaN    0.008237\n",
       "285                    NaN    0.008187\n",
       "141                    NaN    0.008135\n",
       "108                    NaN    0.008006\n",
       "40                     NaN    0.007993\n",
       "140                    NaN    0.007829\n",
       "1                 BuyItNow    0.007788\n",
       "17                     NaN    0.007551\n",
       "199                    NaN    0.007307\n",
       "339                    NaN    0.007250"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc_model = ExtraTreesClassifier()\n",
    "etc_model.fit(X_train_p, y_train_c)\n",
    "etc_model.\n",
    "#print(etc_model.feature_importances_)\n",
    "feature_list = pd.concat([pd.Series(X.columns), pd.Series(etc_model.feature_importances_)], axis=1)\n",
    "feature_list.columns = ['features_name', 'importance']\n",
    "feature_list.sort_values(\"importance\", ascending =False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polish-revision",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), array([False, False, False,  True,  True, False, False, False, False,\n       False, False, False, False, False, False,  True,  True, False,\n       False, False, False, False, False, False, False, False, False,\n        True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n        True, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True,  True,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n        True, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-897ebe5b53c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Num Features: {fit.n_features_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Selected features: {X[:,fit.support_]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Feature Ranking: {fit.ranking_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 )\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), array([False, False, False,  True,  True, False, False, False, False,\n       False, False, False, False, False, False,  True,  True, False,\n       False, False, False, False, False, False, False, False, False,\n        True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n        True, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True,  True,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n        True, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]))' is an invalid key"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 20)\n",
    "fit = rfe.fit(X_train_p, y_train_c)\n",
    "\n",
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "print(f\"Selected features: {X[:,fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complicated-launch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1188, 560), (1188, 20))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_p.shape, rfe.transform(X_train_p).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-reasoning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "arctic-syntax",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 20\n",
      "Feature Ranking: [459  10   3   1   1 401 380 275 377 248 305  22  56 389 283   1   1  71\n",
      " 450 325 441 114  78  97 477 219 429   1   1 301 416 252  63 357 175 411\n",
      " 196 197  58 117 458 431   1  36  45   1 206   8  55  80  15 355 406 419\n",
      "   1 360 310 229 332 304 448 253  53 473 290 204 225 165 447  33 113 386\n",
      " 145  34 257 268 444 184  62 465 494 115 222 430 337 452 394 190 480 158\n",
      " 354 498 151 511 286 361 522 439 453 228 330 478 139 538 132  40  67  65\n",
      "   9 141  72  37 217  79 417 128  11 284 168   4  14 369 328 334 216 322\n",
      " 314   1  44 368 230 289  95  29 485 212 246 313  26 155   1 126 317  70\n",
      "  69 194 356  96 127 154 131 471  51  66 482 466  50 407 449 162 238 481\n",
      "  38   1 507 104 220 475 462 182 255 135 442 489 134 281 265 446 315  82\n",
      " 474 174 245 432 179 285 218 533 440 502 457 261 343 276 530 463   1   1\n",
      " 338 342 348  94 259 202 306 129 235 183 318 207 391 170 266 346   1  83\n",
      "   1  24  31 157   1 366 490 500 200 349  86  84  54 399 464   7 277 374\n",
      " 352 156  25 339 171 186 323 148 333 232 393  30 140 167 185  28 100 367\n",
      " 438  77 195 123 388 107 239 247 214 427  23 203 375 526 234 307 256 233\n",
      " 166 125 531  32 215 405 300 404 316 351 208 160  43 199 408 418 335 181\n",
      " 193 149 291 288   1 143 512 451 312 172 329 116  99 224 373 227   1  27\n",
      "  46 147 231 150 267  59   6 250 384 365 295 424 279 263 187 344 397 434\n",
      " 270   1 426 103 178 142 241 524 371  81  21  92  88  17 516  47 236  16\n",
      " 513  91  93 260 309 336  57 319 271 390  52 486 109  98 163 499 226 363\n",
      " 437  18 237 137 177  12  60 455 176 110 242 495 130 254 278  42 395 287\n",
      " 345 192 398  89 467 505  61 364 541  85  48 303 331  87 274 532 320 422\n",
      "  74 138 484 211  49 376 272 423 311 173 479 146  20  75 164 213  90 198\n",
      " 249  19 101  13 223 497 302 209 508 370 159 341 180 108 210 470 161 520\n",
      " 372 340 402 144 299 324 515 400 414 240 358 169 136 297 326 421 294 119\n",
      " 420 493 102 347 413 282 468 403 258 460 118  68  35 105 121 454 205 528\n",
      " 112 433 350 383 298 221 534 327  64  76 385 456 153 111 379 501   5 504\n",
      " 435 308 496 445 133 106 122  39 483 535 269 296  73 188 487 292 540 280\n",
      " 359 409 264 387 378  41 461 251 410 189 120 415 539 509 362 243 436 244\n",
      " 469 536 191 293 492 201 510 392 503 517   2 381 273 412 152 506 521 353\n",
      " 396 537 476 425 525 527 523 488 514 472 321 262 443 382 518 491 124 519\n",
      " 529 428]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "#print(f\"Selected features: {X[:, fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(X_train_p, y_train_c)\n",
    "\n",
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "print(f\"Selected features: {X.columns[fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "hairy-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 560 out of 560 | elapsed:  2.2min finished\n",
      "Features: 559/20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 559 out of 559 | elapsed:  1.9min finished\n",
      "Features: 558/20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 558 out of 558 | elapsed:  1.8min finished\n",
      "Features: 557/20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   38.2s\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    }
   ],
   "source": [
    "# Install mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "selector = SequentialFeatureSelector(LogisticRegression(), scoring='accuracy', \n",
    "                                     verbose=1, k_features=20, forward=False, n_jobs=-1)\n",
    "selector.fit(X_train_p, y_train_c)\n",
    "selected_f = selector.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-flight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-appearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-norfolk",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "annoying-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neighbors = np.linspace(1, 101, num=50).astype(int)\n",
    "test_contams = np.linspace(0.01, 0.3, num=30)\n",
    "best_params, best_acc, X2, y2 = 0, 0, 0, 0\n",
    "\n",
    "def tune_lof_xgb(model, df, scaler=None, poly=None, dim_reduction=None, ref=None):\n",
    "    best_params, best_acc, X2, y2 = 0, 0, 0, 0\n",
    "    for i, tn in enumerate(test_neighbors):\n",
    "        for j, tc in enumerate(test_contams):\n",
    "            \n",
    "            clf = LocalOutlierFactor(n_neighbors=tn, contamination=tc)\n",
    "            y_pred = clf.fit_predict(df.drop('sold', axis=1))\n",
    "            lof_outlier_idx = pd.Series(y_pred)[pd.Series(y_pred)==-1].index\n",
    "            df_lof2 = df.drop(lof_outlier_idx)\n",
    "            \n",
    "            X2 = df_lof2.drop('sold', axis=1)\n",
    "            y2 = df_lof2.sold\n",
    "            X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y2,\n",
    "                                                                    random_state=11)\n",
    "            X2_train, X2_valid, y2_train, y2_valid = train_test_split(X2_train, y2_train,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y2_train,\n",
    "                                                                    random_state=11)\n",
    "            \n",
    "            if scaler:\n",
    "                X2_train = scaler.fit_transform(X2_train)\n",
    "                X2_valid = scaler.transform(X2_valid)\n",
    "                X2_test = scaler.transform(X2_test)\n",
    "                \n",
    "            if poly:\n",
    "                X2_train = poly.fit_transform(X2_train)\n",
    "                X2_valid = poly.transform(X2_valid)\n",
    "                X2_test = poly.transform(X2_test)\n",
    "            \n",
    "            if dim_reduction:\n",
    "                X2_train = dim_reduction.fit_transform(X2_train)\n",
    "                X2_valid = dim_reduction.transform(X2_valid)\n",
    "                X2_test = dim_reduction.transform(X2_test)\n",
    "                \n",
    "            if ref:\n",
    "                X2_train = ref.fit_transform(X2_train)\n",
    "                X2_valid = ref.transform(X2_valid)\n",
    "                X2_test = ref.transform(X2_test)\n",
    "            \n",
    "            mod = model\n",
    "            mod.fit(X2_train, y2_train, early_stopping_rounds=50, eval_metric=\"error\",\n",
    "                 eval_set=[(X2_train, y2_train), (X2_valid, y2_valid)], verbose=0)\n",
    "            mod_acc = accuracy_score(y2_test, mod.predict(X2_test))\n",
    "            if best_acc < mod_acc:\n",
    "                best_acc = mod_acc\n",
    "                best_params = (tn, tc)\n",
    "                X2 = X2\n",
    "                y2 = y2\n",
    "                print((i, j, tn, tc, best_acc))\n",
    "    \n",
    "    return best_params, best_acc, X2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
    "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
    "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
    "              interaction_constraints=None, learning_rate=0.1,\n",
    "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
    "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
    "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
    "              random_state=None, rate_drop=0.3500000000000001, reg_alpha=None,\n",
    "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
    "              skip_drop=0.30000000000000004, subsample=0.7, tree_method=None,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "separate-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1, 0.01, 0.8129251700680272)\n",
      "(0, 1, 1, 0.019999999999999997, 0.8178694158075601)\n",
      "(0, 2, 1, 0.03, 0.8194444444444444)\n",
      "(0, 4, 1, 0.049999999999999996, 0.8368794326241135)\n",
      "(3, 6, 7, 0.06999999999999999, 0.8375451263537906)\n",
      "(3, 8, 7, 0.08999999999999998, 0.8413284132841329)\n",
      "(4, 28, 9, 0.29, 0.8483412322274881)\n",
      "(9, 22, 19, 0.22999999999999998, 0.851528384279476)\n",
      "(18, 24, 37, 0.24999999999999997, 0.852017937219731)\n",
      "(29, 26, 60, 0.26999999999999996, 0.8617511520737328)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60, 0.26999999999999996), 0.8617511520737328)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best = grid7.best_params_['classifier']\n",
    "xgb_scaler = MinMaxScaler()\n",
    "xgb_poly = PolynomialFeatures(degree=3)\n",
    "xgb_rfe = RFE(RandomForestClassifier(),\n",
    "              n_features_to_select=140)\n",
    "xgb_lof_tune = tune_lof_xgb(xgb_best, df,\n",
    "                                  scaler=xgb_scaler,\n",
    "                                  poly=xgb_poly)\n",
    "xgb_lof_tune[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-incidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-better",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-brazil",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
