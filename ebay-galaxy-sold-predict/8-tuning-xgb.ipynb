{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "willing-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn. neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.stats import expon, reciprocal\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from missingpy import MissForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "front-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/galaxy_final.csv', index_col=0)\n",
    "X = df.drop('sold', axis=1)\n",
    "y = df.sold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11,\n",
    "                                                       stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-welcome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-modeling",
   "metadata": {},
   "source": [
    "# XGBoost Tuning\n",
    "- https://www.kaggle.com/lifesailor/xgboost\n",
    "- https://brunch.co.kr/@snobberys/137\n",
    "- https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "\n",
    "General Parameter\n",
    "- booster: tree 기반 모델 / 선형 모델\n",
    "    - https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "    - skip_drop(default = 0, range [0, 1]) is the probability of skipping dropout. It has a higher priority than other DART parameters.\n",
    "        - If skip_drop = 1, the dropout procedure would be skipped and dart is the same as gbtree.\n",
    "    - If skip_drop≠0, rate_drop (default = 0, range [0, 1]) will drop a fraction of the trees before the model update in every iteration.\n",
    "        - dropout makes dart between gbtree and random forest: “If no tree is dropped, dart is the same as (gbtree); if all the trees are dropped, dart is no different than random forest.”\n",
    "- silent: 메세지 조절\n",
    "- nthread: 병렬 처리 조절\n",
    "\n",
    "Boost Parameter\n",
    "- eta: Learning rate(일반적으로 0.01 - 0.2)\n",
    "- min_child_weight: min_child_weight를 기준으로 추가 분기 결정(크면 Underfitting)\n",
    "- max_depth: Tree 깊이 수\n",
    "- max_leaf_node: 하나의 트리에서 node 개수\n",
    "- gamma: split 하기 위한 최소의 loss 감소 정의\n",
    "- subsample: 데이터 중 샘플링(0.5 - 1)\n",
    "- colsample_bytree: column 중 sampling(0.5 - 1)\n",
    "- colsample_bylevel: 각 level마다 샘플링 비율\n",
    "- lambda: L2 nrom\n",
    "- alpha: L1 norm\n",
    "- scale_pos_weight: positive, negative weight 지정\n",
    "- 기타 등\n",
    "\n",
    "Learning Task Parameter\n",
    "- object: 목적함수 종류\n",
    "    - binary:logistic(이진 분류)\n",
    "    - multi:softmax(다중 분류)\n",
    "    - multi-softprob(다중 확률)\n",
    "- eval_metric: 평가 지표\n",
    "    - rmse – root mean square error\n",
    "    - mae – mean absolute error\n",
    "    - logloss – negative log-likelihood\n",
    "    - error – Binary classification error rate (0.5 threshold)\n",
    "    - merror – Multiclass classification error rate\n",
    "    - mlogloss – Multiclass logloss\n",
    "    - auc: Area under the curve\n",
    "seed\n",
    "\n",
    "### Overview\n",
    "- high learning rate(0.05 - 0.3)를 선택하고 이 학습률에 맞는 tree 개수를 선정한다.\n",
    "- tree-specific parameter를 수정한다.\n",
    "- max_depth, min_child_weight, gamma, subsample, colsample_bytree\n",
    "- regularization parameter를 수정한다.\n",
    "- 학습률을 낮추고 다시 반복한다.\n",
    "\n",
    "### Initialization\n",
    "초기값은 다음과 같이 선정한다.\n",
    "- max_depth = 5: 보통 4-6 를 시작점으로 한다.\n",
    "- min_child_weight = 1 : 향후에 튜닝할 것이다.\n",
    "- gamma = 0 : 0.1 - 0.2로 시작해도 된다. 그런데 어짜피 튜닝할 것이다.\n",
    "- subsample, colsample_bytree = 0.8 : 보통 0.5 - 0.9로 시작한다.\n",
    "- scale_pos_weight = 1: Because of high class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-bermuda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "industrial-bloom",
   "metadata": {},
   "source": [
    "### 1-1. Scaler + PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polish-instrumentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8047193560968692\n"
     ]
    }
   ],
   "source": [
    "pipe1_1 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "             ] \n",
    "grid1_1 = GridSearchCV(pipe1_1, param_grid1_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_1.fit(X_train, y_train)\n",
    "print(grid1_1.best_params_)\n",
    "print(grid1_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-might",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "instant-introduction",
   "metadata": {},
   "source": [
    "### 1-2. Scaler Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surprised-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'scale': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "0.7971492394426125\n"
     ]
    }
   ],
   "source": [
    "pipe1_2 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_2 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "             ] \n",
    "grid1_2 = GridSearchCV(pipe, param_grid1_2, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_2.fit(X_train, y_train)\n",
    "print(grid1_2.best_params_)\n",
    "print(grid1_2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-prescription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-suggestion",
   "metadata": {},
   "source": [
    "### 1-3. Scale -> Poly -> ReduceDim\n",
    "\n",
    "- PCA & LDA\n",
    "    - https://huidea.tistory.com/126\n",
    "- LDA\n",
    "    - https://yamalab.tistory.com/41\n",
    "    - http://www.datamarket.kr/xe/board_oFxn34/26649\n",
    "- TSNE\n",
    "    - https://agiantmind.tistory.com/215\n",
    "    - https://lovit.github.io/nlp/representation/2018/09/28/tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "concerned-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 64.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=1, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 1, 'reduce_dims': PCA(copy=True, iterated_power='auto', n_components=9, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'reduce_dims__n_components': 9, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.7887281494876431\n"
     ]
    }
   ],
   "source": [
    "pipe1_3 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()),\n",
    "                ('reduce_dims', PCA()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_3 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree': [1, 2, 3],\n",
    "               'reduce_dims' : [PCA(), LDA(), TSNE()],\n",
    "               'reduce_dims__n_components' : [5, 7, 9, 11]\n",
    "              }\n",
    "             ] \n",
    "grid1_3 = GridSearchCV(pipe1_3, param_grid1_3, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_3.fit(X_train, y_train)\n",
    "print(grid1_3.best_params_)\n",
    "print(grid1_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-default",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naughty-vegetarian",
   "metadata": {},
   "source": [
    "### 1-4. Scale -> Poly -> Feature Selection\n",
    "\n",
    "```python\n",
    "len(PolynomialFeatures(3).fit_transform(X_train)[0, :]) = 560\n",
    "```\n",
    "- 280\n",
    "- 140\n",
    "- 70\n",
    "- 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-currency",
   "metadata": {},
   "source": [
    "# REF estimator로 XGBClassifier 사용한다면?\n",
    "- https://gentlej90.tistory.com/86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "agricultural-satin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 162.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'feature_selection': RFE(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                     class_weight=None, criterion='gini',\n",
      "                                     max_depth=None, max_features='auto',\n",
      "                                     max_leaf_nodes=None, max_samples=None,\n",
      "                                     min_impurity_decrease=0.0,\n",
      "                                     min_impurity_split=None,\n",
      "                                     min_samples_leaf=1, min_samples_split=2,\n",
      "                                     min_weight_fraction_leaf=0.0,\n",
      "                                     n_estimators=100, n_jobs=None,\n",
      "                                     oob_score=False, random_state=None,\n",
      "                                     verbose=0, warm_start=False),\n",
      "    n_features_to_select=140, step=1, verbose=0), 'feature_selection__n_features_to_select': 140, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "0.8080913378009431\n"
     ]
    }
   ],
   "source": [
    "pipe1_4 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(LogisticRegression())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_4 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree': [1, 2, 3],\n",
    "               'feature_selection' : [RFE(LogisticRegression()),\n",
    "                                     RFE(RandomForestClassifier())],\n",
    "               'feature_selection__n_features_to_select' : [280, 140, 70, 35]\n",
    "#                'reduce_dims' : [PCA(), LDA(), TSNE()],\n",
    "#                'reduce_dims__n_components' : [5, 7, 9, 11]\n",
    "              }\n",
    "             ]\n",
    "grid1_4 = GridSearchCV(pipe1_4, param_grid1_4, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_4.fit(X_train, y_train)\n",
    "print(grid1_4.best_params_)\n",
    "print(grid1_4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-grove",
   "metadata": {},
   "source": [
    "### Scaler+Poly+RFE + Poly > Scaler Only > Scaler + Poly + DimReduction\n",
    "- 0.808 > 0.805 > 0.797 > 0.789\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thorough-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid1_3 base, grid1_4 base 두 가지로 파라미터 튜닝 진행\n",
    "# grid1_4를 위해, Scaler-poly-rfe 완료한 데이터를 미리 생성 (매번 만들지 않도록)\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "# X_train_c, X_valid_c, y_train_c, y_valid_c = train_test_split(X_train_c, y_train_c,\n",
    "#                                                                     test_size=0.2,\n",
    "#                                                                     shuffle=True,\n",
    "#                                                                     stratify=y_train_c,\n",
    "#                                                                     random_state=11)\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "rfe = RFE(RandomForestClassifier(), n_features_to_select=140)\n",
    "\n",
    "X_train_c = scaler.fit_transform(X_train_c)\n",
    "# X_valid_c = scaler.transform(X_valid_c)\n",
    "X_test_c = scaler.transform(X_test_c)\n",
    "\n",
    "X_train_c = poly.fit_transform(X_train_c)\n",
    "# X_valid_c = poly.transform(X_valid_c)\n",
    "X_test_c = poly.transform(X_test_c)\n",
    "\n",
    "X_train_c = rfe.fit_transform(X_train_c, y_train_c)\n",
    "# X_valid_c = rfe.transform(X_valid_c)\n",
    "X_test_c = rfe.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "christian-quality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "heavy-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1188, 13), (1188, 560), (1188, 140))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, poly.transform(X_train).shape, X_train_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-lawrence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "first-population",
   "metadata": {},
   "source": [
    "### max_depth, min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "transparent-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8106229833705635\n"
     ]
    }
   ],
   "source": [
    "# grid1_3 base (scaler-poly-xgb)\n",
    "# max_depth와 min_child_weight를 튜닝한다.\n",
    "\n",
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid2 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':range(3,10,3),\n",
    "               'classifier__min_child_weight':range(1,6,2),\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid2 = GridSearchCV(pipe, param_grid2, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid2.fit(X_train, y_train)\n",
    "print(grid2.best_params_)\n",
    "print(grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "promotional-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8}\n",
      "0.8097897386802823\n"
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# max_depth와 min_child_weight를 튜닝한다.\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "#                 ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid2_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':range(3,10,3),\n",
    "               'classifier__min_child_weight':range(1,6,2),\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "#                'scale':[MinMaxScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#                'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "#                'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid2_1 = GridSearchCV(pipe_1_4, param_grid2_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid2_1.fit(X_train_c, y_train_c)\n",
    "print(grid2_1.best_params_)\n",
    "print(grid2_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-extreme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-breathing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "female-court",
   "metadata": {},
   "source": [
    "### Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mediterranean-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8106229833705635\n"
     ]
    }
   ],
   "source": [
    "# grid1_3 base (scaler-poly-xgb)\n",
    "# Gamma를 튜닝한다.\n",
    "param_grid3 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[i/10.0 for i in range(0,10)],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid3 = GridSearchCV(pipe, param_grid3, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid3.fit(X_train, y_train)\n",
    "print(grid3.best_params_)\n",
    "print(grid3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "insured-terrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.7, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.7, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8}\n",
      "0.8173740382228841\n"
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# Gamma 튜닝\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "#                 ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid3_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2_1.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2_1.best_params_['classifier__min_child_weight']],# 5\n",
    "               'classifier__gamma':[i/10.0 for i in range(0,10)],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "#                'scale':[MinMaxScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#                'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "#                'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid3_1 = GridSearchCV(pipe_1_4, param_grid3_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid3_1.fit(X_train_c, y_train_c)\n",
    "print(grid3_1.best_params_)\n",
    "print(grid3_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-guide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beginning-header",
   "metadata": {},
   "source": [
    "### subsample, colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "empty-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8156791830656314\n"
     ]
    }
   ],
   "source": [
    "# subsample and colsample_bytree를 튜닝한다.\n",
    "param_grid4 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid4 = GridSearchCV(pipe, param_grid4, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid4.fit(X_train, y_train)\n",
    "print(grid4.best_params_)\n",
    "print(grid4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surprised-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 15.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.7, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.7, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8}\n",
      "0.8173740382228841\n"
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# subsample and colsample_bytree를 튜닝한다.\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "#                 ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid4_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2_1.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2_1.best_params_['classifier__min_child_weight']],# 5\n",
    "               'classifier__gamma':[grid3_1.best_params_['classifier__gamma']], # 0.7\n",
    "               'classifier__subsample':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "#                'scale':[MinMaxScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#                'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "#                'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid4_1 = GridSearchCV(pipe_1_4, param_grid4_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid4_1.fit(X_train_c, y_train_c)\n",
    "print(grid4_1.best_params_)\n",
    "print(grid4_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-valve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-journal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "textile-ambassador",
   "metadata": {},
   "source": [
    "### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fitted-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8156791830656314\n"
     ]
    }
   ],
   "source": [
    "# n_estimators 튜닝\n",
    "\n",
    "param_grid5 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[50, 100, 300, 500, 750, 1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid5 = GridSearchCV(pipe, param_grid5, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid5.fit(X_train, y_train)\n",
    "print(grid5.best_params_)\n",
    "print(grid5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-layout",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "secure-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.7, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=700, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.7, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 700, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8}\n",
      "0.8190547104917917\n"
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# n_estimator 튜닝\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "#                 ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid5_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[10, 300, 500, 700, 1000, 2000, 3000],\n",
    "               'classifier__max_depth': [grid2_1.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2_1.best_params_['classifier__min_child_weight']],# 5\n",
    "               'classifier__gamma':[grid3_1.best_params_['classifier__gamma']], # 0.7\n",
    "               'classifier__subsample':[grid4_1.best_params_['classifier__subsample']], # 0.8\n",
    "               'classifier__colsample_bytree':[grid4_1.best_params_['classifier__colsample_bytree']], # 0.8\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "#                'scale':[MinMaxScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#                'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "#                'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid5_1 = GridSearchCV(pipe_1_4, param_grid5_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid5_1.fit(X_train_c, y_train_c)\n",
    "print(grid5_1.best_params_)\n",
    "print(grid5_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-haven",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-handling",
   "metadata": {},
   "source": [
    "### rate_drop, skip_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "devoted-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 96.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.3500000000000001, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
      "              skip_drop=0.30000000000000004, subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.3500000000000001, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.30000000000000004, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8165124277559125\n"
     ]
    }
   ],
   "source": [
    "# rate_drop, skip_drop 튜닝\n",
    "param_grid6 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': np.arange(0.1, 0.55, 0.05),\n",
    "              'classifier__skip_drop': np.arange(0.1, 0.55, 0.05),\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[grid5.best_params_['classifier__n_estimators']], # 1000\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid6 = GridSearchCV(pipe, param_grid6, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid6.fit(X_train, y_train)\n",
    "print(grid6.best_params_)\n",
    "print(grid6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "contained-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 38.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.7, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=700, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.25000000000000006, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
      "              skip_drop=0.25000000000000006, subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.7, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 700, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.25000000000000006, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.25000000000000006, 'classifier__subsample': 0.8}\n",
      "0.8198915009041592\n"
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# rate_drop, skip_drop 튜닝\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "#                 ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid6_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': np.arange(0.1, 0.55, 0.05),\n",
    "              'classifier__skip_drop': np.arange(0.1, 0.55, 0.05),\n",
    "               'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[grid5_1.best_params_['classifier__n_estimators']], # 700\n",
    "               'classifier__max_depth': [grid2_1.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2_1.best_params_['classifier__min_child_weight']],# 5\n",
    "               'classifier__gamma':[grid3_1.best_params_['classifier__gamma']], # 0.7\n",
    "               'classifier__subsample':[grid4_1.best_params_['classifier__subsample']], # 0.8\n",
    "               'classifier__colsample_bytree':[grid4_1.best_params_['classifier__colsample_bytree']], # 0.8\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "#                'scale':[MinMaxScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#                'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "#                'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid6_1 = GridSearchCV(pipe_1_4, param_grid6_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid6_1.fit(X_train_c, y_train_c)\n",
    "print(grid6_1.best_params_)\n",
    "print(grid6_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-boating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-arrangement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "superior-gravity",
   "metadata": {},
   "source": [
    "### learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "prescription-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.3500000000000001, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
      "              skip_drop=0.30000000000000004, subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.3500000000000001, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.30000000000000004, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8165124277559125\n"
     ]
    }
   ],
   "source": [
    "# learning rate\n",
    "\n",
    "param_grid7 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [grid6.best_params_['classifier__rate_drop']], \n",
    "              'classifier__skip_drop': [grid6.best_params_['classifier__skip_drop']], \n",
    "             'classifier__learning_rate': [0.005, 0.01, 0.03, 0.05, 0.1],\n",
    "             'classifier__n_estimators':[grid5.best_params_['classifier__n_estimators']], # 1000\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ]\n",
    "grid7 = GridSearchCV(pipe, param_grid7, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid7.fit(X_train, y_train)\n",
    "print(grid7.best_params_)\n",
    "print(grid7.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adequate-belize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.7, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=700, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.25000000000000006, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
      "              skip_drop=0.25000000000000006, subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.7, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 5, 'classifier__n_estimators': 700, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.25000000000000006, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.25000000000000006, 'classifier__subsample': 0.8}\n",
      "0.8198915009041592\n"
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# learning rate 튜닝\n",
    "\n",
    "pipe_1_4 = Pipeline([\n",
    "#                 ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "#                 ('feature_selection', RFE(RandomForestClassifier())),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid7_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [grid6_1.best_params_['classifier__rate_drop']], # 0.25\n",
    "              'classifier__skip_drop': [grid6_1.best_params_['classifier__skip_drop']], # 0.25\n",
    "               'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "             'classifier__n_estimators':[grid5_1.best_params_['classifier__n_estimators']], # 700\n",
    "               'classifier__max_depth': [grid2_1.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2_1.best_params_['classifier__min_child_weight']],# 5\n",
    "               'classifier__gamma':[grid3_1.best_params_['classifier__gamma']], # 0.7\n",
    "               'classifier__subsample':[grid4_1.best_params_['classifier__subsample']], # 0.8\n",
    "               'classifier__colsample_bytree':[grid4_1.best_params_['classifier__colsample_bytree']], # 0.8\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "#                'scale':[MinMaxScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[3],\n",
    "#                'feature_selection' : [RFE(RandomForestClassifier())],\n",
    "#                'feature_selection__n_features_to_select' : [140]\n",
    "              }\n",
    "             ]\n",
    "grid7_1 = GridSearchCV(pipe_1_4, param_grid7_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid7_1.fit(X_train_c, y_train_c)\n",
    "print(grid7_1.best_params_)\n",
    "print(grid7_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dirty-guarantee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
       "              gamma=0.7, gpu_id=None, importance_type='gain',\n",
       "              interaction_constraints=None, learning_rate=0.1,\n",
       "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=700, n_jobs=-1,\n",
       "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
       "              random_state=None, rate_drop=0.25000000000000006, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
       "              skip_drop=0.25000000000000006, subsample=0.8, tree_method=None, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid7_1.best_params_['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rental-birthday",
   "metadata": {},
   "source": [
    "### Early Stopping Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alike-catering",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-075018fbdc6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX_test_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mX_train_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mX_valid_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mX_test_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         indices = _generate_sample_indices(tree.random_state, n_samples,\n\u001b[0;32m--> 154\u001b[0;31m                                            n_samples_bootstrap)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[0;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    117\u001b[0m     Private function used to _parallel_build_trees function.\"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mrandom_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0msample_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.BitGenerator.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.get_assembled_entropy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit - early stopping rounds\n",
    "#xgb_best = grid7.best_estimator_[2]\n",
    "xgb_best = XGBClassifier(booster='dart', colsample_bytree=0.9, eval_metric='error',\n",
    "              gamma=0.0, importance_type='gain', learning_rate=0.1,\n",
    "              max_depth=3, min_child_weight=1,\n",
    "              n_estimators=1000, n_jobs=-1,\n",
    "              nthread=-1, objective='binary:logistic',\n",
    "              rate_drop=0.3500000000000001, \n",
    "              scale_pos_weight=1, seed=2021,\n",
    "              skip_drop=0.30000000000000004, subsample=0.7)\n",
    "\n",
    "best_esr_stoprounds = (-1, -1)\n",
    "for i, esr in enumerate(np.arange(50, 550, 50)):\n",
    "    X_train_c, X_test_c, y_train_c, y_test_c = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "    X_train_c, X_valid_c, y_train_c, y_valid_c = train_test_split(X_train_c, y_train_c,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y_train_c,\n",
    "                                                                    random_state=11)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    \n",
    "    X_train_c = scaler.fit_transform(X_train_c)\n",
    "    X_valid_c = scaler.transform(X_valid_c)\n",
    "    X_test_c = scaler.transform(X_test_c)\n",
    "    \n",
    "    X_train_c = poly.fit_transform(X_train_c)\n",
    "    X_valid_c = poly.transform(X_valid_c)\n",
    "    X_test_c = poly.transform(X_test_c)\n",
    "    \n",
    "    xgb_best.fit(X_train_c, y_train_c, early_stopping_rounds=esr, eval_metric=\"error\",\n",
    "                 eval_set=[(X_train_c, y_train_c), (X_valid_c, y_valid_c)], verbose=0)\n",
    "    acc = accuracy_score(y_test, xgb_best.predict(X_test_c))\n",
    "    \n",
    "    if acc > best_esr_stoprounds[1]:\n",
    "        best_esr_stoprounds = (esr, acc)\n",
    "        print(i, best_esr_stoprounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dense-mineral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 0.8383838383838383)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_esr_stoprounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-broadway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dirty-geometry",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaleing-poly-rfe completed\n",
      "0/(50, 0.8249158249158249)\n",
      "1/2/3/4/5/6/7/8/9/"
     ]
    }
   ],
   "source": [
    "# grid1_4 base (scaler-poly-rfe-xgb)\n",
    "# early stop test\n",
    "\n",
    "# xgb_best_c = XGBClassifier(booster='dart', colsample_bytree=0.9, eval_metric='error',\n",
    "#               gamma=0.0, importance_type='gain', learning_rate=0.1,\n",
    "#               max_depth=3, min_child_weight=1,\n",
    "#               n_estimators=1000, n_jobs=-1,\n",
    "#               nthread=-1, objective='binary:logistic',\n",
    "#               rate_drop=0.3500000000000001, \n",
    "#               scale_pos_weight=1, seed=2021,\n",
    "#               skip_drop=0.30000000000000004, subsample=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "guided-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/(50, 0.8249158249158249)\n",
      "1/2/3/4/5/6/7/8/9/"
     ]
    }
   ],
   "source": [
    "xgb_best_c = grid7_1.best_params_['classifier']\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "X_train_c, X_valid_c, y_train_c, y_valid_c = train_test_split(X_train_c, y_train_c,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y_train_c,\n",
    "                                                                    random_state=11)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "rfe = RFE(RandomForestClassifier(), n_features_to_select=140)\n",
    "\n",
    "X_train_c = scaler.fit_transform(X_train_c)\n",
    "X_valid_c = scaler.transform(X_valid_c)\n",
    "X_test_c = scaler.transform(X_test_c)\n",
    "\n",
    "X_train_c = poly.fit_transform(X_train_c)\n",
    "X_valid_c = poly.transform(X_valid_c)\n",
    "X_test_c = poly.transform(X_test_c)\n",
    "\n",
    "X_train_c = rfe.fit_transform(X_train_c, y_train_c)\n",
    "X_valid_c = rfe.transform(X_valid_c)\n",
    "X_test_c = rfe.transform(X_test_c)\n",
    "\n",
    "best_esr_stoprounds_rfe = (-1, -1)\n",
    "for i, esr in enumerate(np.arange(50, 550, 50)):\n",
    "    print(i, end='/')\n",
    "    xgb_best_c = grid7_1.best_params_['classifier']\n",
    "    xgb_best_c.fit(X_train_c, y_train_c, early_stopping_rounds=esr, eval_metric=\"error\",\n",
    "                 eval_set=[(X_train_c, y_train_c), (X_valid_c, y_valid_c)], verbose=0)\n",
    "    acc = accuracy_score(y_test, xgb_best_c.predict(X_test_c))\n",
    "    \n",
    "    if acc > best_esr_stoprounds_rfe[1]:\n",
    "        best_esr_stoprounds_rfe = (esr, acc)\n",
    "        print(best_esr_stoprounds_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "distant-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/(10, 0.8316498316498316)\n",
      "1/2/3/4/5/6/7/8/9/"
     ]
    }
   ],
   "source": [
    "# 2nd try\n",
    "for i, esr in enumerate(np.arange(10, 110, 10)):\n",
    "    print(i, end='/')\n",
    "    xgb_best_c = grid7_1.best_params_['classifier']\n",
    "    xgb_best_c.fit(X_train_c, y_train_c, early_stopping_rounds=esr, eval_metric=\"error\",\n",
    "                 eval_set=[(X_train_c, y_train_c), (X_valid_c, y_valid_c)], verbose=0)\n",
    "    acc = accuracy_score(y_test, xgb_best_c.predict(X_test_c))\n",
    "    \n",
    "    if acc > best_esr_stoprounds_rfe[1]:\n",
    "        best_esr_stoprounds_rfe = (esr, acc)\n",
    "        print(best_esr_stoprounds_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-entry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intensive-filter",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hindu-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()\n",
    "X_train_c = scaler.fit_transform(X_train_c)\n",
    "X_test_c = scaler.transform(X_test_c)\n",
    "X_train_p = poly.fit_transform(X_train_c)\n",
    "X_test_p = poly.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "direct-seventh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 560)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_c[0, :]), len(X_train_p[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "closing-regular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>startprice</td>\n",
       "      <td>0.039908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>productSeries_imputed</td>\n",
       "      <td>0.016792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BuyItNow</td>\n",
       "      <td>0.007788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             features_name  importance\n",
       "2               startprice    0.039908\n",
       "27                     NaN    0.026178\n",
       "196                    NaN    0.020621\n",
       "16                     NaN    0.019841\n",
       "3    productSeries_imputed    0.016792\n",
       "38                     NaN    0.015045\n",
       "207                    NaN    0.013881\n",
       "29                     NaN    0.013553\n",
       "107                    NaN    0.012192\n",
       "118                    NaN    0.011159\n",
       "274                    NaN    0.011039\n",
       "39                     NaN    0.010202\n",
       "273                    NaN    0.010083\n",
       "130                    NaN    0.009622\n",
       "105                    NaN    0.009202\n",
       "106                    NaN    0.009051\n",
       "119                    NaN    0.008993\n",
       "275                    NaN    0.008923\n",
       "14                     NaN    0.008737\n",
       "131                    NaN    0.008241\n",
       "28                     NaN    0.008237\n",
       "285                    NaN    0.008187\n",
       "141                    NaN    0.008135\n",
       "108                    NaN    0.008006\n",
       "40                     NaN    0.007993\n",
       "140                    NaN    0.007829\n",
       "1                 BuyItNow    0.007788\n",
       "17                     NaN    0.007551\n",
       "199                    NaN    0.007307\n",
       "339                    NaN    0.007250"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc_model = ExtraTreesClassifier()\n",
    "etc_model.fit(X_train_p, y_train_c)\n",
    "etc_model.\n",
    "#print(etc_model.feature_importances_)\n",
    "feature_list = pd.concat([pd.Series(X.columns), pd.Series(etc_model.feature_importances_)], axis=1)\n",
    "feature_list.columns = ['features_name', 'importance']\n",
    "feature_list.sort_values(\"importance\", ascending =False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aerial-tampa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), array([False, False, False,  True,  True, False, False, False, False,\n       False, False, False, False, False, False,  True,  True, False,\n       False, False, False, False, False, False, False, False, False,\n        True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n        True, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True,  True,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n        True, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-897ebe5b53c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Num Features: {fit.n_features_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Selected features: {X[:,fit.support_]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Feature Ranking: {fit.ranking_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 )\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), array([False, False, False,  True,  True, False, False, False, False,\n       False, False, False, False, False, False,  True,  True, False,\n       False, False, False, False, False, False, False, False, False,\n        True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n        True, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True,  True,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n        True, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]))' is an invalid key"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 20)\n",
    "fit = rfe.fit(X_train_p, y_train_c)\n",
    "\n",
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "print(f\"Selected features: {X[:,fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legitimate-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1188, 560), (1188, 20))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_p.shape, rfe.transform(X_train_p).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-magazine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "royal-dispatch",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 20\n",
      "Feature Ranking: [459  10   3   1   1 401 380 275 377 248 305  22  56 389 283   1   1  71\n",
      " 450 325 441 114  78  97 477 219 429   1   1 301 416 252  63 357 175 411\n",
      " 196 197  58 117 458 431   1  36  45   1 206   8  55  80  15 355 406 419\n",
      "   1 360 310 229 332 304 448 253  53 473 290 204 225 165 447  33 113 386\n",
      " 145  34 257 268 444 184  62 465 494 115 222 430 337 452 394 190 480 158\n",
      " 354 498 151 511 286 361 522 439 453 228 330 478 139 538 132  40  67  65\n",
      "   9 141  72  37 217  79 417 128  11 284 168   4  14 369 328 334 216 322\n",
      " 314   1  44 368 230 289  95  29 485 212 246 313  26 155   1 126 317  70\n",
      "  69 194 356  96 127 154 131 471  51  66 482 466  50 407 449 162 238 481\n",
      "  38   1 507 104 220 475 462 182 255 135 442 489 134 281 265 446 315  82\n",
      " 474 174 245 432 179 285 218 533 440 502 457 261 343 276 530 463   1   1\n",
      " 338 342 348  94 259 202 306 129 235 183 318 207 391 170 266 346   1  83\n",
      "   1  24  31 157   1 366 490 500 200 349  86  84  54 399 464   7 277 374\n",
      " 352 156  25 339 171 186 323 148 333 232 393  30 140 167 185  28 100 367\n",
      " 438  77 195 123 388 107 239 247 214 427  23 203 375 526 234 307 256 233\n",
      " 166 125 531  32 215 405 300 404 316 351 208 160  43 199 408 418 335 181\n",
      " 193 149 291 288   1 143 512 451 312 172 329 116  99 224 373 227   1  27\n",
      "  46 147 231 150 267  59   6 250 384 365 295 424 279 263 187 344 397 434\n",
      " 270   1 426 103 178 142 241 524 371  81  21  92  88  17 516  47 236  16\n",
      " 513  91  93 260 309 336  57 319 271 390  52 486 109  98 163 499 226 363\n",
      " 437  18 237 137 177  12  60 455 176 110 242 495 130 254 278  42 395 287\n",
      " 345 192 398  89 467 505  61 364 541  85  48 303 331  87 274 532 320 422\n",
      "  74 138 484 211  49 376 272 423 311 173 479 146  20  75 164 213  90 198\n",
      " 249  19 101  13 223 497 302 209 508 370 159 341 180 108 210 470 161 520\n",
      " 372 340 402 144 299 324 515 400 414 240 358 169 136 297 326 421 294 119\n",
      " 420 493 102 347 413 282 468 403 258 460 118  68  35 105 121 454 205 528\n",
      " 112 433 350 383 298 221 534 327  64  76 385 456 153 111 379 501   5 504\n",
      " 435 308 496 445 133 106 122  39 483 535 269 296  73 188 487 292 540 280\n",
      " 359 409 264 387 378  41 461 251 410 189 120 415 539 509 362 243 436 244\n",
      " 469 536 191 293 492 201 510 392 503 517   2 381 273 412 152 506 521 353\n",
      " 396 537 476 425 525 527 523 488 514 472 321 262 443 382 518 491 124 519\n",
      " 529 428]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "#print(f\"Selected features: {X[:, fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(X_train_p, y_train_c)\n",
    "\n",
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "print(f\"Selected features: {X.columns[fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "combined-hampshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 560 out of 560 | elapsed:  2.2min finished\n",
      "Features: 559/20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 559 out of 559 | elapsed:  1.9min finished\n",
      "Features: 558/20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 558 out of 558 | elapsed:  1.8min finished\n",
      "Features: 557/20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   38.2s\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    }
   ],
   "source": [
    "# Install mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "selector = SequentialFeatureSelector(LogisticRegression(), scoring='accuracy', \n",
    "                                     verbose=1, k_features=20, forward=False, n_jobs=-1)\n",
    "selector.fit(X_train_p, y_train_c)\n",
    "selected_f = selector.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-arabic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-patient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "recovered-performance",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "legitimate-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid1_3 base\n",
    "# lof for original data (df) : non-scaled & non-poly\n",
    "\n",
    "def tune_lof_xgb(model, df, scaler=None, poly=None, dim_reduction=None, ref=None):\n",
    "    test_neighbors = np.linspace(1, 101, num=50).astype(int)\n",
    "    test_contams = np.linspace(0.01, 0.3, num=30)\n",
    "    best_params, best_acc, X2, y2 = 0, 0, 0, 0\n",
    "    \n",
    "    for i, tn in enumerate(test_neighbors):\n",
    "        for j, tc in enumerate(test_contams):\n",
    "            \n",
    "            clf = LocalOutlierFactor(n_neighbors=tn, contamination=tc)\n",
    "            y_pred = clf.fit_predict(df.drop('sold', axis=1))\n",
    "            lof_outlier_idx = pd.Series(y_pred)[pd.Series(y_pred)==-1].index\n",
    "            df_lof2 = df.drop(lof_outlier_idx)\n",
    "            \n",
    "            X2 = df_lof2.drop('sold', axis=1)\n",
    "            y2 = df_lof2.sold\n",
    "            X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y2,\n",
    "                                                                    random_state=11)\n",
    "            X2_train, X2_valid, y2_train, y2_valid = train_test_split(X2_train, y2_train,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y2_train,\n",
    "                                                                    random_state=11)\n",
    "            \n",
    "            if scaler:\n",
    "                X2_train = scaler.fit_transform(X2_train)\n",
    "                X2_valid = scaler.transform(X2_valid)\n",
    "                X2_test = scaler.transform(X2_test)\n",
    "                \n",
    "            if poly:\n",
    "                X2_train = poly.fit_transform(X2_train)\n",
    "                X2_valid = poly.transform(X2_valid)\n",
    "                X2_test = poly.transform(X2_test)\n",
    "            \n",
    "            if dim_reduction:\n",
    "                X2_train = dim_reduction.fit_transform(X2_train)\n",
    "                X2_valid = dim_reduction.transform(X2_valid)\n",
    "                X2_test = dim_reduction.transform(X2_test)\n",
    "                \n",
    "            if ref:\n",
    "                X2_train = ref.fit_transform(X2_train, y2_train)\n",
    "                X2_valid = ref.transform(X2_valid)\n",
    "                X2_test = ref.transform(X2_test)\n",
    "            \n",
    "            mod = model\n",
    "            mod.fit(X2_train, y2_train, early_stopping_rounds=50, eval_metric=\"error\",\n",
    "                 eval_set=[(X2_train, y2_train), (X2_valid, y2_valid)], verbose=0)\n",
    "            mod_acc = accuracy_score(y2_test, mod.predict(X2_test))\n",
    "            if best_acc < mod_acc:\n",
    "                best_acc = mod_acc\n",
    "                best_params = (tn, tc)\n",
    "                X2 = X2\n",
    "                y2 = y2\n",
    "                print((i, j, tn, tc, best_acc))\n",
    "    \n",
    "    return best_params, best_acc, X2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interior-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
    "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
    "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
    "              interaction_constraints=None, learning_rate=0.1,\n",
    "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=np.nan,\n",
    "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
    "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
    "              random_state=None, rate_drop=0.3500000000000001, reg_alpha=None,\n",
    "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
    "              skip_drop=0.30000000000000004, subsample=0.7, tree_method=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "violent-project",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1, 0.01, 0.8095238095238095)\n",
      "(0, 2, 1, 0.03, 0.8159722222222222)\n",
      "(0, 4, 1, 0.049999999999999996, 0.8368794326241135)\n",
      "(0, 10, 1, 0.10999999999999997, 0.8377358490566038)\n",
      "(2, 0, 5, 0.01, 0.8401360544217688)\n",
      "(4, 25, 9, 0.25999999999999995, 0.8409090909090909)\n",
      "(4, 27, 9, 0.27999999999999997, 0.8551401869158879)\n",
      "(29, 26, 60, 0.26999999999999996, 0.8617511520737328)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60, 0.26999999999999996), 0.8617511520737328)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb_best = grid7.best_params_['classifier']\n",
    "xgb_scaler = RobustScaler()\n",
    "xgb_poly = PolynomialFeatures(degree=3)\n",
    "# xgb_rfe = RFE(RandomForestClassifier(),\n",
    "#               n_features_to_select=140)\n",
    "xgb_lof_tune = tune_lof_xgb(xgb_best, df,\n",
    "                                  scaler=xgb_scaler,\n",
    "                                  poly=xgb_poly)\n",
    "xgb_lof_tune[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-hospital",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "invalid-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lof_xgb2(model, df, stoprounds=50,\n",
    "                  scaler=None, poly=None, dim_reduction=None, rfe=None,\n",
    "                  preset=False):    \n",
    "    best_params, best_acc = 0, 0    \n",
    "    test_neighbors = np.linspace(1, 101, num=50).astype(int)\n",
    "    test_contams = np.linspace(0.01, 0.3, num=30)\n",
    "    \n",
    "    if preset:\n",
    "        X0_train, X0_valid, X0_test, y0_train, y0_valid, y0_test = df\n",
    "        \n",
    "    else:\n",
    "        X0 = df.drop('sold', axis=1)\n",
    "        y0 = df.sold\n",
    "        X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0,\n",
    "                                                                test_size=0.2,\n",
    "                                                                shuffle=True,\n",
    "                                                                stratify=y0,\n",
    "                                                                random_state=11)\n",
    "        X0_train, X0_valid, y0_train, y0_valid = train_test_split(X0_train, y0_train,\n",
    "                                                                test_size=0.2,\n",
    "                                                                shuffle=True,\n",
    "                                                                stratify=y0_train,\n",
    "                                                                random_state=11)\n",
    "\n",
    "        if scaler:\n",
    "            X0_train = scaler.fit_transform(X0_train)\n",
    "            X0_valid = scaler.transform(X0_valid)\n",
    "            X0_test = scaler.transform(X0_test)\n",
    "\n",
    "        if poly:\n",
    "            X0_train = poly.fit_transform(X0_train)\n",
    "            X0_valid = poly.transform(X0_valid)\n",
    "            X0_test = poly.transform(X0_test)\n",
    "\n",
    "        if dim_reduction:\n",
    "            X0_train = dim_reduction.fit_transform(X0_train)\n",
    "            X0_valid = dim_reduction.transform(X0_valid)\n",
    "            X0_test = dim_reduction.transform(X0_test)\n",
    "\n",
    "        if rfe:\n",
    "            X0_train = rfe.fit_transform(X0_train, y0_train)\n",
    "            X0_valid = rfe.transform(X0_valid)\n",
    "            X0_test = rfe.transform(X0_test)\n",
    "\n",
    "        print('preprocessing complete')\n",
    "    \n",
    "    for i, tn in enumerate(test_neighbors):\n",
    "        for j, tc in enumerate(test_contams):\n",
    "            \n",
    "            # 원본 보존을 위해 복사본 사용\n",
    "            X_train_copy, X_valid_copy, X_test_copy = X0_train.copy(), X0_valid.copy(), X0_test.copy()\n",
    "            y_train_copy, y_valid_copy, y_test_copy = y0_train.copy(), y0_valid.copy(), y0_test.copy()\n",
    "            \n",
    "            # LOF 모델 생성 및 트레인셋 학습\n",
    "            clf = LocalOutlierFactor(n_neighbors=tn, contamination=tc,\n",
    "                                    novelty=True)\n",
    "            clf.fit(X_train_copy)\n",
    "            \n",
    "            # 트레인셋 아웃라이어 제거\n",
    "            y_pred = clf.predict(X_train_copy)\n",
    "            lof_outlier_idx_train = pd.Series(y_pred)[pd.Series(y_pred)==-1].index\n",
    "            X_train_copy = pd.DataFrame(X_train_copy).drop(lof_outlier_idx_train)\n",
    "            y_train_copy = y_train_copy.reset_index(drop=True).drop(lof_outlier_idx_train)\n",
    "            \n",
    "            # 밸리데이션 셋 아웃라이어 제거\n",
    "            yval_pred = clf.predict(X_valid_copy)\n",
    "            lof_outlier_idx_valid = pd.Series(yval_pred)[pd.Series(yval_pred)==-1].index\n",
    "            X_valid_copy = pd.DataFrame(X_valid_copy).drop(lof_outlier_idx_valid)\n",
    "            y_valid_copy = y_valid_copy.reset_index(drop=True).drop(lof_outlier_idx_valid)\n",
    "            \n",
    "            # 테스트 셋 아웃라이어 제거\n",
    "            ytest_pred = clf.predict(X_test_copy)\n",
    "            lof_outlier_idx_test = pd.Series(ytest_pred)[pd.Series(ytest_pred)==-1].index\n",
    "            X_test_copy = pd.DataFrame(X_test_copy).drop(lof_outlier_idx_test)\n",
    "            y_test_copy = y_test_copy.reset_index(drop=True).drop(lof_outlier_idx_test)\n",
    "            \n",
    "            # 예측모델 정의 및 트레인/벨리데이션 셋으로 학습\n",
    "            mod = model\n",
    "            mod.fit(X_train_copy, y_train_copy, early_stopping_rounds=stoprounds, eval_metric=\"error\",\n",
    "                 eval_set=[(X_train_copy, y_train_copy), (X_valid_copy, y_valid_copy)], verbose=0)\n",
    "            \n",
    "            # 테스트 정확도 측정 및 최고기록 업데이트\n",
    "            mod_acc = accuracy_score(y_test_copy, mod.predict(X_test_copy))\n",
    "            if best_acc < mod_acc:\n",
    "                best_acc = mod_acc\n",
    "                best_params = (tn, tc)\n",
    "#                 X2 = X2\n",
    "#                 y2 = y2\n",
    "                print((i, j, tn, tc, best_acc))\n",
    "    \n",
    "    return {'best_params':best_params,\n",
    "           'best_accuracy':best_acc,\n",
    "           'preprocessed_data':[X0_train, X0_valid, X0_test, y0_train, y0_valid, y0_test],\n",
    "           'LOF_data':[X_train_copy, X_valid_copy, X_test_copy,\n",
    "                      y_train_copy, y_valid_copy, y_test_copy]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "italic-orientation",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing complete\n",
      "(0, 0, 1, 0.01, 0.8082191780821918)\n",
      "(0, 2, 1, 0.03, 0.8096885813148789)\n",
      "(0, 3, 1, 0.039999999999999994, 0.8105263157894737)\n",
      "(0, 4, 1, 0.049999999999999996, 0.8120567375886525)\n",
      "(0, 5, 1, 0.05999999999999999, 0.8122743682310469)\n",
      "(0, 8, 1, 0.08999999999999998, 0.8164794007490637)\n",
      "(0, 9, 1, 0.09999999999999998, 0.8181818181818182)\n",
      "(0, 10, 1, 0.10999999999999997, 0.8185328185328186)\n",
      "(1, 1, 3, 0.019999999999999997, 0.823728813559322)\n",
      "(1, 2, 3, 0.03, 0.8247422680412371)\n",
      "(1, 5, 3, 0.05999999999999999, 0.8257839721254355)\n",
      "(1, 10, 3, 0.10999999999999997, 0.8302583025830258)\n",
      "(1, 18, 3, 0.18999999999999997, 0.836)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-332369738956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m xgb_lof_tune = tune_lof_xgb2(xgb_best, df,\n\u001b[1;32m     10\u001b[0m                                   \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_scaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                   poly=xgb_poly)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mxgb_lof_tune\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-17af3cbdf586>\u001b[0m in \u001b[0;36mtune_lof_xgb2\u001b[0;34m(model, df, scaler, poly, dim_reduction, ref)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             mod.fit(X_train_copy, y_train_copy, early_stopping_rounds=50, eval_metric=\"error\",\n\u001b[0;32m---> 71\u001b[0;31m                  eval_set=[(X_train_copy, y_train_copy), (X_valid_copy, y_valid_copy)], verbose=0)\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# 테스트 정확도 측정 및 최고기록 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    913\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1280\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# grid1_3 base\n",
    "# lof for preprocessed data (scaled & poly applied)\n",
    "\n",
    "xgb_best = XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
    "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
    "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
    "              interaction_constraints=None, learning_rate=0.1,\n",
    "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=np.nan,\n",
    "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
    "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
    "              random_state=None, rate_drop=0.3500000000000001, reg_alpha=None,\n",
    "              reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
    "              skip_drop=0.30000000000000004, subsample=0.7, tree_method=None,)\n",
    "\n",
    "test_neighbors = np.linspace(1, 101, num=50).astype(int)\n",
    "test_contams = np.linspace(0.01, 0.3, num=30)\n",
    "\n",
    "xgb_scaler = RobustScaler()\n",
    "xgb_poly = PolynomialFeatures(degree=3)\n",
    "xgb_lof_tune = tune_lof_xgb2(xgb_best, df,\n",
    "                                  scaler=xgb_scaler,\n",
    "                                  poly=xgb_poly)\n",
    "xgb_lof_tune['best_params'], xgb_lof_tune['best_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-lounge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid1_4 base (+rfe)\n",
    "# lof for preprocessed data (scaled & poly applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid7_1.best_params_['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adult-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing complete\n",
      "(0, 0, 1, 0.01, 0.8316151202749141)\n",
      "(0, 2, 1, 0.03, 0.8321678321678322)\n",
      "(0, 3, 1, 0.039999999999999994, 0.8333333333333334)\n",
      "(0, 18, 1, 0.18999999999999997, 0.8367346938775511)\n",
      "(0, 19, 1, 0.19999999999999998, 0.8403361344537815)\n",
      "(0, 21, 1, 0.21999999999999997, 0.8405172413793104)\n",
      "(1, 5, 3, 0.05999999999999999, 0.85)\n",
      "(1, 12, 3, 0.12999999999999998, 0.8532818532818532)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3, 0.12999999999999998), 0.8532818532818532)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb_best_c = grid7_1.best_params_['classifier']\n",
    "xgb_best_c = XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
    "                          colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
    "                          gamma=0.7, gpu_id=None, importance_type='gain',\n",
    "                          interaction_constraints=None, learning_rate=0.1,\n",
    "                          max_delta_step=None, max_depth=3, min_child_weight=5, missing=np.nan,\n",
    "                          monotone_constraints=None, n_estimators=700, n_jobs=-1,\n",
    "                          nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
    "                          random_state=None, rate_drop=0.25000000000000006, reg_alpha=None,\n",
    "                          reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
    "                          skip_drop=0.25000000000000006, subsample=0.8, tree_method=None)\n",
    "\n",
    "xgb_scaler = MinMaxScaler()\n",
    "xgb_poly = PolynomialFeatures(degree=3)\n",
    "xgb_rfe = RFE(RandomForestClassifier(),\n",
    "              n_features_to_select=140)\n",
    "xgb_lof_tune2 = tune_lof_xgb2(xgb_best_c, df,\n",
    "                              stoprounds=10,\n",
    "                              scaler=xgb_scaler,\n",
    "                              poly=xgb_poly,\n",
    "                              rfe=xgb_rfe)\n",
    "xgb_lof_tune2['best_params'], xgb_lof_tune2['best_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-transparency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "elementary-geology",
   "metadata": {},
   "source": [
    "### what if: RFE using XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "collected-requirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing complete\n",
      "(0, 0, 1, 0.01, 0.8350515463917526)\n",
      "(0, 1, 1, 0.019999999999999997, 0.8368055555555556)\n",
      "(0, 2, 1, 0.03, 0.8385964912280702)\n",
      "(0, 9, 1, 0.09999999999999998, 0.8388278388278388)\n",
      "(1, 1, 3, 0.019999999999999997, 0.8401360544217688)\n",
      "(1, 18, 3, 0.18999999999999997, 0.85)\n",
      "(1, 20, 3, 0.20999999999999996, 0.8516949152542372)\n",
      "(1, 21, 3, 0.21999999999999997, 0.8547008547008547)\n",
      "(1, 22, 3, 0.22999999999999998, 0.8558951965065502)\n",
      "(1, 23, 3, 0.23999999999999996, 0.8565022421524664)\n",
      "(3, 18, 7, 0.18999999999999997, 0.8647540983606558)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7, 0.18999999999999997), 0.8647540983606558)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RFE estimator == XGBClassifier일때 성능 더 나오면\n",
    "# 다시 처음부터 parameter tuning 진행해보기\n",
    "\n",
    "xgb_best_c = XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
    "                          colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
    "                          gamma=0.7, gpu_id=None, importance_type='gain',\n",
    "                          interaction_constraints=None, learning_rate=0.1,\n",
    "                          max_delta_step=None, max_depth=3, min_child_weight=5, missing=np.nan,\n",
    "                          monotone_constraints=None, n_estimators=700, n_jobs=-1,\n",
    "                          nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
    "                          random_state=None, rate_drop=0.25000000000000006, reg_alpha=None,\n",
    "                          reg_lambda=None, scale_pos_weight=1, seed=2021,\n",
    "                          skip_drop=0.25000000000000006, subsample=0.8, tree_method=None)\n",
    "\n",
    "xgb_scaler = MinMaxScaler()\n",
    "xgb_poly = PolynomialFeatures(degree=3)\n",
    "xgb_rfe = RFE(XGBClassifier(objective='binary:logistic',\n",
    "                           eval_metric='error'),\n",
    "              n_features_to_select=140)\n",
    "xgb_lof_tune3 = tune_lof_xgb2(xgb_best_c, df,\n",
    "                              stoprounds=10,\n",
    "                              scaler=xgb_scaler,\n",
    "                              poly=xgb_poly,\n",
    "                              rfe=xgb_rfe)\n",
    "\n",
    "xgb_lof_tune3['best_params'], xgb_lof_tune3['best_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-balloon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-appreciation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
