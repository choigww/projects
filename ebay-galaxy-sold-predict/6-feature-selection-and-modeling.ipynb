{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "voluntary-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn. neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.stats import expon, reciprocal\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from missingpy import MissForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-armenia",
   "metadata": {},
   "source": [
    "### (Kaggle) Feature Engineering and Feature Selection\n",
    "- https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection\n",
    "- feature selection 방법들 성능 비교 실험\n",
    "    - https://www.kaggle.com/harangdev/feature-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "descending-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('./data/galaxy_shotgun.csv', index_col=0)\n",
    "df = pd.read_csv('./data/galaxy_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "virtual-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>BuyItNow</th>\n",
       "      <th>startprice</th>\n",
       "      <th>productSeries_imputed</th>\n",
       "      <th>product_isNote_imputed</th>\n",
       "      <th>hasDescription</th>\n",
       "      <th>charCountDescriptionBins</th>\n",
       "      <th>upperCaseDescription_rate</th>\n",
       "      <th>startprice_point9</th>\n",
       "      <th>sold</th>\n",
       "      <th>color_sentiment_0</th>\n",
       "      <th>color_sentiment_1</th>\n",
       "      <th>carrier_none_0</th>\n",
       "      <th>carrier_none_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>235.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>199.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>175.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>89.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>1481</td>\n",
       "      <td>0</td>\n",
       "      <td>239.95</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1482</td>\n",
       "      <td>0</td>\n",
       "      <td>329.99</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1483</td>\n",
       "      <td>0</td>\n",
       "      <td>89.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>1484</td>\n",
       "      <td>0</td>\n",
       "      <td>119.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1485 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  BuyItNow  startprice  productSeries_imputed  \\\n",
       "0         0         0      199.99                      2   \n",
       "1         1         0      235.00                      2   \n",
       "2         2         0      199.99                      1   \n",
       "3         3         1      175.00                      2   \n",
       "4         4         1      100.00                      1   \n",
       "...     ...       ...         ...                    ...   \n",
       "1480   1480         0       89.50                      0   \n",
       "1481   1481         0      239.95                      2   \n",
       "1482   1482         0      329.99                      3   \n",
       "1483   1483         0       89.00                      0   \n",
       "1484   1484         0      119.99                      0   \n",
       "\n",
       "      product_isNote_imputed  hasDescription  charCountDescriptionBins  \\\n",
       "0                          0               0                         0   \n",
       "1                          1               0                         0   \n",
       "2                          0               1                         1   \n",
       "3                          1               0                         0   \n",
       "4                          0               0                         0   \n",
       "...                      ...             ...                       ...   \n",
       "1480                       0               1                         1   \n",
       "1481                       0               1                         1   \n",
       "1482                       1               1                         1   \n",
       "1483                       0               1                         1   \n",
       "1484                       0               1                         1   \n",
       "\n",
       "      upperCaseDescription_rate  startprice_point9  sold  color_sentiment_0  \\\n",
       "0                      0.000000                  1     1                  1   \n",
       "1                      0.000000                  0     0                  0   \n",
       "2                      0.020000                  1     0                  0   \n",
       "3                      0.000000                  0     1                  0   \n",
       "4                      0.000000                  0     1                  0   \n",
       "...                         ...                ...   ...                ...   \n",
       "1480                   0.020833                  0     0                  0   \n",
       "1481                   0.051546                  1     1                  0   \n",
       "1482                   0.010753                  1     0                  0   \n",
       "1483                   0.021739                  0     1                  0   \n",
       "1484                   0.052083                  1     0                  0   \n",
       "\n",
       "      color_sentiment_1  carrier_none_0  carrier_none_1  \n",
       "0                     0               0               1  \n",
       "1                     0               0               1  \n",
       "2                     0               0               0  \n",
       "3                     1               1               0  \n",
       "4                     1               0               1  \n",
       "...                 ...             ...             ...  \n",
       "1480                  0               1               0  \n",
       "1481                  1               0               1  \n",
       "1482                  1               0               1  \n",
       "1483                  1               0               1  \n",
       "1484                  1               1               0  \n",
       "\n",
       "[1485 rows x 14 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "olive-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = df0.drop(['sold', 'carrier','color', 'startprice_standardized',\n",
    "             'startprice_minmax', 'noDescription', 'productline',\n",
    "             'productline_imputed', 'productline_imputed2'], axis=1)\n",
    "y0 = df0.sold\n",
    "X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0, test_size=0.2, random_state=11,\n",
    "                                                       stratify=y0, shuffle=True)\n",
    "\n",
    "X = df.drop('sold', axis=1)\n",
    "y = df.sold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11,\n",
    "                                                       stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-blond",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "annoying-carrier",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-solomon",
   "metadata": {},
   "source": [
    "### LIGHTGBM 이란? 그리고 PARAMETER 튜닝하기\n",
    "- https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/\n",
    "- http://machinelearningkorea.com/2019/09/29/lightgbm-파라미터/\n",
    "\n",
    "---\n",
    "- ask : 데이터에 대해서 수행하고자 하는 임무를 구체화합니다. train 트레이닝일 수도 있고 predict 예측일 수도 있습니다.\n",
    "\n",
    "- application : 가장 중요한 파라미터로, 모델의 어플리케이션을 정하는데 이것이 regression 회귀분석 문제인지 또는 classification 분류 문제인지를 정합니다. Light GBM에서 디폴트는 regression 회귀분석 모델입니다.\n",
    "    - regression: 회귀분석\n",
    "    - binary: 이진 분류\n",
    "    - multiclass: 다중 분류\n",
    "\n",
    "- boosting : 실행하고자 하는 알고리즘 타입을 정의합니다. 디폴트값은 gdbt 입니다.\n",
    "    - gdbt : Traditional Gradient Boosting Decision Tree\n",
    "    - rf : Random Forest\n",
    "    - dart : Dropouts meet Multiple Additive Regression Trees\n",
    "    - goss : Gradient-based One-Side Sampling\n",
    "\n",
    "- num_boost_round : boosting iteration 수로 일반적으로 100 이상입니다.\n",
    "\n",
    "- learning_rate : 최종 결과에 대한 각각의 Tree에 영향을 미치는 변수입니다. GBM은 초기의 추정값에서 시작하여 각각의Tree 결과를 사용하여 추정값을 업데이트 합니다. 학습 파라미터는 이러한 추정에서 발생하는 변화의 크기를 컨트롤합니다. 일반적인 값은 0.1, 0.001, 0.003 등등이 있습니다.\n",
    "\n",
    "- num_leaves : 전체 Tree의 leave 수 이고, 디폴트값은 31입니다.\n",
    "\n",
    "- device : 디폴트 값은 cpu 인데 gpu로 변경할 수도 있습니다.\n",
    "\n",
    "\n",
    "- metric : 모델을 구현할 때 손실을 정하기 때문에 중요한 변수 중에 하나입니다. regression과 classification 을 위한 일반적인 손실 값이 아래에 나와있습니다.\n",
    "\n",
    "    - mae : mean absolute error\n",
    "    - mse : mean squared error\n",
    "    - binary_logloss : loss for binary classification\n",
    "    - multi_logloss : loss for multi classification\n",
    "\n",
    "- max_bin : feature 값의 최대 bin 수를 의미합니다.\n",
    "- categorical_feature : 범주형 feature의 인덱스를 의미합니다. 만약 categorical_features 가 0, 1, 2 이면 column 0, column 1, column 2 가 범주형 변수들입니다.\n",
    "- ignore_column : categorical_features와 동일한 것인데 범주형 feature로써 특정 칼럼을 고려하지 않는 것입니다. 그 변수들을 무시하는 것입니다.\n",
    "- save_binary : 데이터 파일의 메모리 사이즈를 처리해야 한다면 이 파라미터 값을 True로 설정하십시오. 이 값을 True로 세팅하면 데이터 세트를 바이너리 파일로 저장할 것이고, 이 바이너리 파일은 다음에 데이터를 읽어올 때 그 속도를 줄여줄 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "clear-winning",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 248832 candidates, totalling 1244160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 18.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-25ee5bf47815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     verbose=1, n_jobs=-1)\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI_dev/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', LGBMClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid = [\n",
    "#                 {'classifier': [LogisticRegression()],\n",
    "#                'classifier__penalty': ['l1', 'l2'], \n",
    "#                'classifier__C': [0.0001, 0.01, 0.1, 1, 100, 1000],\n",
    "#                'scale': [MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[1, 2, 3]\n",
    "#                },\n",
    "              \n",
    "              {'classifier': [LGBMClassifier()],\n",
    "              'classifier__max_depth': [3, 5, 7, 9],\n",
    "              'classifier__num_leaves':[2**2-1, 2**4-1, 2**5-1, 2**7-1],\n",
    "              'classifier__min_child_samples': [10, 15],\n",
    "              'classifier__subsample': [0.25, 0.5, 0.75, 1],\n",
    "             'classifier__learning_rate':[0.03, 0.1],\n",
    "             'classifier__n_estimators':[64, 128, 256],\n",
    "               'classifier__application':['binary'],\n",
    "               'classifier__metric':['binary_logloss'],\n",
    "               'classifier__categorical_feature':[[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12]],\n",
    "               'classifier__feature_fraction':[0.7, 0.9, 1],\n",
    "               'classifier__boosting_type':['gbdt', 'dart'],\n",
    "               'classifier__num_iterations':[1000, 3000],\n",
    "               'classifier__drop_rate':[0.1, 0.2, 0.3],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "              \n",
    "#               {'classifier': [Ridge()],\n",
    "#                'classifier__alpha' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#                'scale': [MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[1, 2, 3]               \n",
    "#                },\n",
    "#               {'classifier': [XGBRegressor()],\n",
    "#               'classifier__learning_rate': [0.001, 0.01, 0.1] ,\n",
    "#             'classifier__max_depth': [3, 6, 9],\n",
    "#             'classifier__min_child_weight' : [3, 5, 7],\n",
    "#             'classifier__gamma'            : [0.1, 0.3, 0.5],\n",
    "#             'classifier__colsample_bytree' : [0.3, 0.5 , 0.7],\n",
    "#             'classifier__n_estimators':[64, 256, 1024]\n",
    "#               }\n",
    "             \n",
    "             ] # min_samples_split: The minimum number of samples required to split an internal node       \n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-holder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "military-sensitivity",
   "metadata": {},
   "source": [
    "# SVM Tuning\n",
    "- [서포트 벡터 머신(SVM)의 사용자로서 꼭 알아야할 것들 - 매개변수 C와 gamma](https://bskyvision.com/163)\n",
    "    - [SVM model selection – how to adjust all these knobs pt. 1](https://tomaszkacmajor.pl/index.php/2016/04/24/svm-model-selection/)\n",
    "    - [SVM model selection – how to adjust all these knobs pt. 2](https://tomaszkacmajor.pl/index.php/2016/05/01/svm-model-selection2/)\n",
    "    - [Data preprocessing for SVM classifier](https://tomaszkacmajor.pl/index.php/2016/04/24/data-preprocessing/)\n",
    "    \n",
    "### 차원축소\n",
    "http://www.datamarket.kr/xe/board_oFxn34/26649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "boring-samoa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 728 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1118 out of 1125 | elapsed:   23.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1125 out of 1125 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scale',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('reduce_dims',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=7, random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('clf',\n",
       "                                        SVC(C=0.0001, break_ties...\n",
       "                         'clf__gamma': [0.0001, 0.1, 1, 100, 1000],\n",
       "                         'clf__kernel': ['rbf'],\n",
       "                         'reduce_dims__n_components': [7, 9, 11],\n",
       "                         'scale': [MinMaxScaler(copy=True,\n",
       "                                                feature_range=(0, 1)),\n",
       "                                   StandardScaler(copy=True, with_mean=True,\n",
       "                                                  with_std=True),\n",
       "                                   RobustScaler(copy=True,\n",
       "                                                quantile_range=(25.0, 75.0),\n",
       "                                                with_centering=True,\n",
       "                                                with_scaling=True)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('reduce_dims', PCA(n_components=7)),\n",
    "        ('clf', svm.SVC(kernel = 'linear', C = 0.0001, gamma=0.0001))])\n",
    "\n",
    "param_grid = dict(reduce_dims__n_components=[7, 9, 11],\n",
    "                  clf__gamma=[0.0001, 0.1, 1, 100, 1000],\n",
    "                  #clf__C=np.logspace(-1, 1, 6),\n",
    "                  clf__C=[0.0001, 0.1, 1, 100, 1000],\n",
    "                  clf__kernel=['rbf'],\n",
    "                 scale=[MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "                 )\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "signed-upper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7845335602595468\n",
      "{'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'rbf', 'reduce_dims__n_components': 7, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-variable",
   "metadata": {},
   "source": [
    "### SVC with Dimension Reduction\n",
    "- PCA & LDA\n",
    "    - https://huidea.tistory.com/126\n",
    "- LDA\n",
    "    - https://yamalab.tistory.com/41\n",
    "    - http://www.datamarket.kr/xe/board_oFxn34/26649\n",
    "- TSNE\n",
    "    - https://agiantmind.tistory.com/215\n",
    "    - https://lovit.github.io/nlp/representation/2018/09/28/tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "beginning-gentleman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4544 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 7344 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9297 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10687 tasks      | elapsed: 12.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7895897599546148\n",
      "{'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf', 'reduce_dims': PCA(copy=True, iterated_power='auto', n_components=11, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'reduce_dims__n_components': 11, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 11520 out of 11520 | elapsed: 36.6min finished\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([\n",
    "        ('scale', MinMaxScaler()),\n",
    "        #('poly', PolynomialFeatures()),\n",
    "        ('reduce_dims', PCA(n_components=5)),\n",
    "        ('clf', svm.SVC(kernel = 'rbf', C = 0.0001, gamma=0.0001))])\n",
    "\n",
    "param_grid2 = dict(clf__gamma=[0.0001, 0.001, 0.1, 1, 10, 100, 1000, 10000],\n",
    "                  clf__C=[0.0001, 0.001, 0.1, 1, 10, 100, 1000, 10000],\n",
    "                  clf__kernel=['rbf'],\n",
    "                  reduce_dims = [PCA(), LDA(), TSNE()],\n",
    "                  reduce_dims__n_components = [5, 7, 9, 11],\n",
    "                  scale = [MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "                  #poly = [PolynomialFeatures()],\n",
    "                  #poly__degree = [1, 2, 3],\n",
    "                  # reduce_dims__n_components=[7, 9, 11]\n",
    "                  )\n",
    "\n",
    "grid2 = GridSearchCV(pipe2, param_grid=param_grid2,\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid2.fit(X_train, y_train)\n",
    "print(grid2.best_score_)\n",
    "print(grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-necklace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "variable-accommodation",
   "metadata": {},
   "source": [
    "# XGBoost Tuning\n",
    "- https://www.kaggle.com/lifesailor/xgboost\n",
    "- https://brunch.co.kr/@snobberys/137\n",
    "- https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "\n",
    "General Parameter\n",
    "- booster: tree 기반 모델 / 선형 모델\n",
    "    - https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "    - skip_drop(default = 0, range [0, 1]) is the probability of skipping dropout. It has a higher priority than other DART parameters.\n",
    "        - If skip_drop = 1, the dropout procedure would be skipped and dart is the same as gbtree.\n",
    "    - If skip_drop≠0, rate_drop (default = 0, range [0, 1]) will drop a fraction of the trees before the model update in every iteration.\n",
    "        - dropout makes dart between gbtree and random forest: “If no tree is dropped, dart is the same as (gbtree); if all the trees are dropped, dart is no different than random forest.”\n",
    "- silent: 메세지 조절\n",
    "- nthread: 병렬 처리 조절\n",
    "\n",
    "Boost Parameter\n",
    "- eta: Learning rate(일반적으로 0.01 - 0.2)\n",
    "- min_child_weight: min_child_weight를 기준으로 추가 분기 결정(크면 Underfitting)\n",
    "- max_depth: Tree 깊이 수\n",
    "- max_leaf_node: 하나의 트리에서 node 개수\n",
    "- gamma: split 하기 위한 최소의 loss 감소 정의\n",
    "- subsample: 데이터 중 샘플링(0.5 - 1)\n",
    "- colsample_bytree: column 중 sampling(0.5 - 1)\n",
    "- colsample_bylevel: 각 level마다 샘플링 비율\n",
    "- lambda: L2 nrom\n",
    "- alpha: L1 norm\n",
    "- scale_pos_weight: positive, negative weight 지정\n",
    "- 기타 등\n",
    "\n",
    "Learning Task Parameter\n",
    "- object: 목적함수 종류\n",
    "    - binary:logistic(이진 분류)\n",
    "    - multi:softmax(다중 분류)\n",
    "    - multi-softprob(다중 확률)\n",
    "- eval_metric: 평가 지표\n",
    "    - rmse – root mean square error\n",
    "    - mae – mean absolute error\n",
    "    - logloss – negative log-likelihood\n",
    "    - error – Binary classification error rate (0.5 threshold)\n",
    "    - merror – Multiclass classification error rate\n",
    "    - mlogloss – Multiclass logloss\n",
    "    - auc: Area under the curve\n",
    "seed\n",
    "\n",
    "### 1. Overview\n",
    "- high learning rate(0.05 - 0.3)를 선택하고 이 학습률에 맞는 tree 개수를 선정한다.\n",
    "- tree-specific parameter를 수정한다.\n",
    "- max_depth, min_child_weight, gamma, subsample, colsample_bytree\n",
    "- regularization parameter를 수정한다.\n",
    "- 학습률을 낮추고 다시 반복한다.\n",
    "\n",
    "### 2. Learning rate와 estimator 수를 고정한다.\n",
    "초기값은 다음과 같이 선정한다.\n",
    "- max_depth = 5: 보통 4-6 를 시작점으로 한다.\n",
    "- min_child_weight = 1 : 향후에 튜닝할 것이다.\n",
    "- gamma = 0 : 0.1 - 0.2로 시작해도 된다. 그런데 어짜피 튜닝할 것이다.\n",
    "- subsample, colsample_bytree = 0.8 : 보통 0.5 - 0.9로 시작한다.\n",
    "- scale_pos_weight = 1: Because of high class imbalance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "super-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, useTrainCV=True,\n",
    "             cv_folds=5, early_stopping_rounds=100):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain['sold'].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'],\n",
    "                          nfold=cv_folds,\n",
    "                          metrics='error',\n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        print(alg)\n",
    "\n",
    "    # Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['sold'], eval_metric='error')\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Training Accuracy : %.4g\" % accuracy_score(dtrain['sold'].values, dtrain_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "wound-european",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=29, n_jobs=-1, nthread=-1,\n",
      "              num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...)\n",
      "\n",
      "Model Report\n",
      "Training Accuracy : 0.867\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "            booster='dart',\n",
    "            rate_drop = 0.15,\n",
    "            skip_drop = 0.33,\n",
    "            learning_rate =0.1,\n",
    "            n_estimators=1000,\n",
    "            max_depth=5,\n",
    "            min_child_weight=1,\n",
    "            gamma=0,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective= 'binary:logistic',\n",
    "            nthread=-1,\n",
    "            scale_pos_weight=1,\n",
    "            seed=2021,\n",
    "            eval_metric='error',\n",
    "            n_jobs=-1\n",
    ")\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "predictors = X.columns\n",
    "target='sold'\n",
    "\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-garden",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "handed-intranet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:  8.1min remaining:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([30.58934498, 26.42062712, 25.18061647, 58.34102116, 47.69806466,\n",
       "         44.90624127, 60.17272582, 54.32366462, 43.40523605]),\n",
       "  'std_fit_time': array([2.16856498, 0.30750746, 1.00604332, 7.35398565, 3.67966623,\n",
       "         4.37471127, 3.27167035, 0.56225405, 7.28937719]),\n",
       "  'mean_score_time': array([0.0107101 , 0.01260343, 0.01409593, 0.03038502, 0.02099056,\n",
       "         0.02123394, 0.01570101, 0.02136602, 0.01830039]),\n",
       "  'std_score_time': array([0.00365702, 0.00747294, 0.00694314, 0.02041759, 0.01062081,\n",
       "         0.00558782, 0.007697  , 0.00872516, 0.00948646]),\n",
       "  'param_max_depth': masked_array(data=[3, 3, 3, 6, 6, 6, 9, 9, 9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
       "   {'max_depth': 3, 'min_child_weight': 3},\n",
       "   {'max_depth': 3, 'min_child_weight': 5},\n",
       "   {'max_depth': 6, 'min_child_weight': 1},\n",
       "   {'max_depth': 6, 'min_child_weight': 3},\n",
       "   {'max_depth': 6, 'min_child_weight': 5},\n",
       "   {'max_depth': 9, 'min_child_weight': 1},\n",
       "   {'max_depth': 9, 'min_child_weight': 3},\n",
       "   {'max_depth': 9, 'min_child_weight': 5}],\n",
       "  'split0_test_score': array([0.75210084, 0.75630252, 0.75630252, 0.7605042 , 0.7605042 ,\n",
       "         0.74789916, 0.7605042 , 0.75210084, 0.75210084]),\n",
       "  'split1_test_score': array([0.78571429, 0.78991597, 0.79831933, 0.79411765, 0.79411765,\n",
       "         0.80672269, 0.79831933, 0.79831933, 0.78571429]),\n",
       "  'split2_test_score': array([0.86134454, 0.84453782, 0.84453782, 0.83613445, 0.82773109,\n",
       "         0.8487395 , 0.82773109, 0.83613445, 0.85294118]),\n",
       "  'split3_test_score': array([0.80168776, 0.82278481, 0.82700422, 0.81012658, 0.82278481,\n",
       "         0.82278481, 0.8185654 , 0.81434599, 0.8185654 ]),\n",
       "  'split4_test_score': array([0.79746835, 0.80590717, 0.81012658, 0.79746835, 0.80590717,\n",
       "         0.79746835, 0.78902954, 0.80168776, 0.79746835]),\n",
       "  'mean_test_score': array([0.79966316, 0.80388966, 0.80725809, 0.79967025, 0.80220898,\n",
       "         0.8047229 , 0.79882991, 0.80051768, 0.80135801]),\n",
       "  'std_test_score': array([0.03541258, 0.02991043, 0.02988072, 0.02453011, 0.02405485,\n",
       "         0.03331444, 0.02362175, 0.02760496, 0.03359477]),\n",
       "  'rank_test_score': array([8, 3, 1, 7, 4, 2, 9, 6, 5], dtype=int32)},\n",
       " {'max_depth': 3, 'min_child_weight': 5},\n",
       " 0.807258093110662)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-2. max_depth와 min_child_weight를 튜닝한다.\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,3),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "xgb2 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = 0.15,\n",
    "    skip_drop = 0.33,\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb2,\n",
    "            param_grid = param_test1, scoring='accuracy',n_jobs=-1,iid=False, cv=5, verbose=10)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "valid-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  25 | elapsed:  3.3min remaining:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([28.2780972 , 31.38163762, 30.85981946, 36.53439283, 30.77492914]),\n",
       "  'std_fit_time': array([ 1.81179902,  0.96373577,  0.83148362,  1.8792291 , 10.35071724]),\n",
       "  'mean_score_time': array([0.0116014 , 0.00939274, 0.01473279, 0.01874571, 0.0106421 ]),\n",
       "  'std_score_time': array([0.00439288, 0.00466556, 0.00877517, 0.0054828 , 0.00736782]),\n",
       "  'param_gamma': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "               mask=[False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'gamma': 0.0},\n",
       "   {'gamma': 0.1},\n",
       "   {'gamma': 0.2},\n",
       "   {'gamma': 0.3},\n",
       "   {'gamma': 0.4}],\n",
       "  'split0_test_score': array([0.75630252, 0.75210084, 0.7605042 , 0.74789916, 0.75630252]),\n",
       "  'split1_test_score': array([0.79831933, 0.78991597, 0.78991597, 0.78991597, 0.78991597]),\n",
       "  'split2_test_score': array([0.84453782, 0.85294118, 0.84453782, 0.8487395 , 0.86134454]),\n",
       "  'split3_test_score': array([0.82700422, 0.8185654 , 0.82278481, 0.8185654 , 0.8185654 ]),\n",
       "  'split4_test_score': array([0.81012658, 0.81434599, 0.81434599, 0.81012658, 0.81434599]),\n",
       "  'mean_test_score': array([0.80725809, 0.80557388, 0.80641776, 0.80304932, 0.80809488]),\n",
       "  'std_test_score': array([0.02988072, 0.03344825, 0.02885911, 0.03344384, 0.0346328 ]),\n",
       "  'rank_test_score': array([2, 4, 3, 5, 1], dtype=int32)},\n",
       " {'gamma': 0.4},\n",
       " 0.8080948835230295)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gamma를 튜닝한다.\n",
    "param_test2 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "xgb3 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = 0.15,\n",
    "    skip_drop = 0.33,\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=gsearch1.best_params_['max_depth'],\n",
    "    min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = xgb3, \n",
    "                        param_grid = param_test2, scoring='accuracy', n_jobs=-1, iid=False, cv=5,\n",
    "                       verbose=10)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "noted-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([33.82177029, 27.43664093, 29.60986733, 27.15421758, 26.78870983,\n",
       "         27.44742198, 26.73164172, 26.73464518, 27.23633585, 27.87654881,\n",
       "         26.71983852, 26.95309052, 26.97949748, 27.14402366, 28.2483561 ,\n",
       "         26.60740142]),\n",
       "  'std_fit_time': array([3.45649065, 0.55654223, 1.14974675, 1.76239089, 0.52037888,\n",
       "         0.69689367, 0.15469292, 0.25769962, 0.84760538, 1.05114453,\n",
       "         0.33462508, 0.22678736, 0.27065149, 0.09254482, 0.64694361,\n",
       "         1.09447646]),\n",
       "  'mean_score_time': array([0.0103168 , 0.00940862, 0.00755582, 0.01154146, 0.02856846,\n",
       "         0.01346722, 0.01066875, 0.01021867, 0.0196106 , 0.01529942,\n",
       "         0.01425109, 0.01114831, 0.01749063, 0.01442151, 0.0139523 ,\n",
       "         0.01209106]),\n",
       "  'std_score_time': array([0.00379985, 0.00434638, 0.00151714, 0.00414223, 0.03022814,\n",
       "         0.00816379, 0.00588096, 0.00446716, 0.01243698, 0.00205384,\n",
       "         0.00527306, 0.00443785, 0.00633983, 0.00665586, 0.00645169,\n",
       "         0.00666618]),\n",
       "  'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.9, 0.9, 0.9, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                     0.9, 0.6, 0.7, 0.8, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
       "  'split0_test_score': array([0.74369748, 0.75630252, 0.7394958 , 0.75210084, 0.74369748,\n",
       "         0.74369748, 0.75630252, 0.75210084, 0.74789916, 0.75210084,\n",
       "         0.75630252, 0.7394958 , 0.75210084, 0.76470588, 0.7605042 ,\n",
       "         0.76890756]),\n",
       "  'split1_test_score': array([0.78571429, 0.80672269, 0.79411765, 0.78991597, 0.80252101,\n",
       "         0.78991597, 0.78571429, 0.78571429, 0.79831933, 0.79831933,\n",
       "         0.78991597, 0.78991597, 0.76470588, 0.79411765, 0.78571429,\n",
       "         0.79831933]),\n",
       "  'split2_test_score': array([0.85714286, 0.85714286, 0.85714286, 0.8487395 , 0.83193277,\n",
       "         0.86134454, 0.86134454, 0.86134454, 0.83193277, 0.83613445,\n",
       "         0.86134454, 0.8697479 , 0.8487395 , 0.84033613, 0.85714286,\n",
       "         0.8697479 ]),\n",
       "  'split3_test_score': array([0.82700422, 0.8185654 , 0.81434599, 0.8185654 , 0.82278481,\n",
       "         0.82700422, 0.81434599, 0.81434599, 0.82278481, 0.8185654 ,\n",
       "         0.8185654 , 0.8185654 , 0.82700422, 0.82700422, 0.8185654 ,\n",
       "         0.8185654 ]),\n",
       "  'split4_test_score': array([0.80168776, 0.81434599, 0.81012658, 0.80168776, 0.79746835,\n",
       "         0.80590717, 0.81434599, 0.81012658, 0.80168776, 0.82278481,\n",
       "         0.81434599, 0.80590717, 0.79324895, 0.80590717, 0.82278481,\n",
       "         0.81434599]),\n",
       "  'mean_test_score': array([0.80304932, 0.81061589, 0.80304578, 0.80220189, 0.79968089,\n",
       "         0.80557388, 0.80641067, 0.80472645, 0.80052477, 0.80558097,\n",
       "         0.80809488, 0.80472645, 0.79715988, 0.80641421, 0.80894231,\n",
       "         0.81397724]),\n",
       "  'std_test_score': array([0.03827518, 0.03227062, 0.03800694, 0.03192127, 0.03072809,\n",
       "         0.03909884, 0.03487932, 0.03593945, 0.02918096, 0.02936303,\n",
       "         0.0346328 , 0.0421784 , 0.03646921, 0.02632752, 0.03314605,\n",
       "         0.03288769]),\n",
       "  'rank_test_score': array([11,  2, 12, 13, 15,  8,  6,  9, 14,  7,  4,  9, 16,  5,  3,  1],\n",
       "        dtype=int32)},\n",
       " {'colsample_bytree': 0.9, 'subsample': 0.9},\n",
       " 0.8139772364642059)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsample and colsample_bytree를 튜닝한다.\n",
    "param_test3 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "xgb4 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = 0.15,\n",
    "    skip_drop = 0.33,\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=gsearch1.best_params_['max_depth'],\n",
    "    min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "    gamma=gsearch2.best_params_['gamma'],\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = xgb4, \n",
    "                        param_grid = param_test3, scoring='accuracy', n_jobs=-1, iid=False, cv=5,\n",
    "                        verbose=10)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "tight-steam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 23.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([34.16247606, 31.28990359, 26.64116697, 26.9349206 , 28.7762085 ,\n",
       "         27.89253793, 26.6632978 , 26.99618554, 26.8220046 , 27.01053514,\n",
       "         27.07244186, 27.09902201, 27.15127153, 30.02572675, 27.03914719,\n",
       "         27.19464259, 27.06251578, 27.11299314, 28.06475592, 29.10566425,\n",
       "         27.01947479, 28.29517817, 28.12519827, 27.12882376, 28.37538166,\n",
       "         29.02653737, 28.06477461, 27.44469957, 27.54322405, 27.97695613,\n",
       "         27.09098935, 27.23149252, 29.90352783, 31.45380397, 27.02714095,\n",
       "         27.02406144, 27.05721059, 27.87606454, 27.30807614, 25.6852428 ]),\n",
       "  'std_fit_time': array([0.36247109, 4.24939446, 0.11956619, 0.22758661, 0.56526648,\n",
       "         1.06494894, 0.27992595, 0.21022993, 0.3087095 , 0.23002698,\n",
       "         0.11252408, 0.33918324, 0.6015456 , 1.08983461, 0.19628117,\n",
       "         0.30900045, 0.20727302, 0.22359157, 1.00758749, 0.91349401,\n",
       "         0.27838073, 1.44648095, 1.16555307, 0.20835624, 2.00616307,\n",
       "         1.92831982, 0.7269082 , 0.6764555 , 0.58870136, 0.53761097,\n",
       "         0.13014027, 0.33044357, 3.3996874 , 3.82762032, 0.22747839,\n",
       "         0.25211662, 0.1534439 , 0.7148083 , 0.40713413, 1.86061032]),\n",
       "  'mean_score_time': array([0.01129594, 0.01477695, 0.01349721, 0.01152849, 0.0164855 ,\n",
       "         0.01630158, 0.0094173 , 0.01450744, 0.01089072, 0.01604147,\n",
       "         0.0109664 , 0.01348615, 0.01533237, 0.02718396, 0.01171446,\n",
       "         0.01448526, 0.01485887, 0.01712804, 0.01276665, 0.01163359,\n",
       "         0.0121047 , 0.01412992, 0.0145154 , 0.01340094, 0.0174428 ,\n",
       "         0.01205211, 0.01591997, 0.0140162 , 0.01428981, 0.01292949,\n",
       "         0.01217661, 0.00959477, 0.01702108, 0.01667709, 0.01644087,\n",
       "         0.01467681, 0.013061  , 0.01293502, 0.01598759, 0.0139842 ]),\n",
       "  'std_score_time': array([0.00473603, 0.00762299, 0.00945083, 0.00443681, 0.00810537,\n",
       "         0.006554  , 0.0048729 , 0.00393266, 0.00530271, 0.0080816 ,\n",
       "         0.00366543, 0.005797  , 0.00643868, 0.02370215, 0.00489008,\n",
       "         0.00410741, 0.00477291, 0.00458726, 0.00580368, 0.00316581,\n",
       "         0.00271335, 0.00336272, 0.00841907, 0.00161899, 0.0044011 ,\n",
       "         0.00368331, 0.00444288, 0.00492427, 0.00571693, 0.00710156,\n",
       "         0.00200793, 0.00232473, 0.00695983, 0.00407201, 0.00526775,\n",
       "         0.00345029, 0.00354145, 0.00430685, 0.00865575, 0.00526763]),\n",
       "  'param_subsample': masked_array(data=[0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48,\n",
       "                     0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57,\n",
       "                     0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66,\n",
       "                     0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,\n",
       "                     0.76, 0.77, 0.78, 0.79],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'subsample': 0.4},\n",
       "   {'subsample': 0.41},\n",
       "   {'subsample': 0.42},\n",
       "   {'subsample': 0.43},\n",
       "   {'subsample': 0.44},\n",
       "   {'subsample': 0.45},\n",
       "   {'subsample': 0.46},\n",
       "   {'subsample': 0.47},\n",
       "   {'subsample': 0.48},\n",
       "   {'subsample': 0.49},\n",
       "   {'subsample': 0.5},\n",
       "   {'subsample': 0.51},\n",
       "   {'subsample': 0.52},\n",
       "   {'subsample': 0.53},\n",
       "   {'subsample': 0.54},\n",
       "   {'subsample': 0.55},\n",
       "   {'subsample': 0.56},\n",
       "   {'subsample': 0.57},\n",
       "   {'subsample': 0.58},\n",
       "   {'subsample': 0.59},\n",
       "   {'subsample': 0.6},\n",
       "   {'subsample': 0.61},\n",
       "   {'subsample': 0.62},\n",
       "   {'subsample': 0.63},\n",
       "   {'subsample': 0.64},\n",
       "   {'subsample': 0.65},\n",
       "   {'subsample': 0.66},\n",
       "   {'subsample': 0.67},\n",
       "   {'subsample': 0.68},\n",
       "   {'subsample': 0.69},\n",
       "   {'subsample': 0.7},\n",
       "   {'subsample': 0.71},\n",
       "   {'subsample': 0.72},\n",
       "   {'subsample': 0.73},\n",
       "   {'subsample': 0.74},\n",
       "   {'subsample': 0.75},\n",
       "   {'subsample': 0.76},\n",
       "   {'subsample': 0.77},\n",
       "   {'subsample': 0.78},\n",
       "   {'subsample': 0.79}],\n",
       "  'split0_test_score': array([0.75210084, 0.74369748, 0.75210084, 0.7394958 , 0.74369748,\n",
       "         0.75210084, 0.75210084, 0.7605042 , 0.7394958 , 0.74789916,\n",
       "         0.74789916, 0.75210084, 0.74789916, 0.75210084, 0.74369748,\n",
       "         0.73109244, 0.74789916, 0.7605042 , 0.75630252, 0.74789916,\n",
       "         0.75210084, 0.75630252, 0.75630252, 0.73529412, 0.75630252,\n",
       "         0.74789916, 0.74369748, 0.7394958 , 0.74789916, 0.76470588,\n",
       "         0.76470588, 0.75630252, 0.75210084, 0.7605042 , 0.75630252,\n",
       "         0.77731092, 0.75210084, 0.7605042 , 0.7605042 , 0.7605042 ]),\n",
       "  'split1_test_score': array([0.79411765, 0.79831933, 0.79411765, 0.77731092, 0.78571429,\n",
       "         0.78571429, 0.80672269, 0.79411765, 0.79411765, 0.79831933,\n",
       "         0.78571429, 0.80672269, 0.78571429, 0.78571429, 0.78151261,\n",
       "         0.79831933, 0.79411765, 0.80672269, 0.79411765, 0.79831933,\n",
       "         0.76470588, 0.79411765, 0.79411765, 0.78991597, 0.76890756,\n",
       "         0.78991597, 0.78991597, 0.78571429, 0.79831933, 0.78151261,\n",
       "         0.79411765, 0.78991597, 0.79831933, 0.79411765, 0.80252101,\n",
       "         0.79411765, 0.78991597, 0.79411765, 0.79831933, 0.79411765]),\n",
       "  'split2_test_score': array([0.84033613, 0.84453782, 0.83613445, 0.8487395 , 0.85294118,\n",
       "         0.83613445, 0.84033613, 0.8487395 , 0.85294118, 0.8487395 ,\n",
       "         0.86554622, 0.85714286, 0.84453782, 0.8487395 , 0.8487395 ,\n",
       "         0.85294118, 0.85714286, 0.86134454, 0.84453782, 0.85294118,\n",
       "         0.8487395 , 0.84453782, 0.8487395 , 0.85714286, 0.85294118,\n",
       "         0.84453782, 0.85294118, 0.84453782, 0.84453782, 0.84033613,\n",
       "         0.84033613, 0.85294118, 0.85714286, 0.85714286, 0.85294118,\n",
       "         0.85714286, 0.85714286, 0.85294118, 0.84033613, 0.85294118]),\n",
       "  'split3_test_score': array([0.81012658, 0.82700422, 0.8185654 , 0.82278481, 0.83122363,\n",
       "         0.8185654 , 0.8185654 , 0.80590717, 0.81012658, 0.8185654 ,\n",
       "         0.80590717, 0.81434599, 0.82278481, 0.8185654 , 0.82278481,\n",
       "         0.82700422, 0.82700422, 0.8185654 , 0.82700422, 0.8185654 ,\n",
       "         0.82700422, 0.8185654 , 0.83122363, 0.83122363, 0.83122363,\n",
       "         0.83122363, 0.82278481, 0.82278481, 0.83966245, 0.83544304,\n",
       "         0.82700422, 0.82700422, 0.82700422, 0.82700422, 0.83544304,\n",
       "         0.81434599, 0.82700422, 0.83544304, 0.81434599, 0.82278481]),\n",
       "  'split4_test_score': array([0.81012658, 0.82278481, 0.82278481, 0.80168776, 0.80168776,\n",
       "         0.81434599, 0.81012658, 0.80590717, 0.79746835, 0.80168776,\n",
       "         0.8185654 , 0.79746835, 0.80168776, 0.80590717, 0.82278481,\n",
       "         0.8185654 , 0.81012658, 0.80590717, 0.81012658, 0.79746835,\n",
       "         0.79324895, 0.79746835, 0.80590717, 0.80168776, 0.81012658,\n",
       "         0.80590717, 0.81012658, 0.81012658, 0.81012658, 0.80590717,\n",
       "         0.80590717, 0.81012658, 0.82278481, 0.81434599, 0.81434599,\n",
       "         0.81012658, 0.80590717, 0.80590717, 0.81012658, 0.8185654 ]),\n",
       "  'mean_test_score': array([0.80136156, 0.80726873, 0.80474063, 0.79800376, 0.80305287,\n",
       "         0.80137219, 0.80557033, 0.80303514, 0.79882991, 0.80304223,\n",
       "         0.80472645, 0.80555615, 0.80052477, 0.80220544, 0.80390384,\n",
       "         0.80558451, 0.80725809, 0.8106088 , 0.80641776, 0.80303868,\n",
       "         0.79715988, 0.80219835, 0.80725809, 0.80305287, 0.80390029,\n",
       "         0.80389675, 0.8038932 , 0.80053186, 0.80810907, 0.80558097,\n",
       "         0.80641421, 0.80725809, 0.81147041, 0.81062298, 0.81231075,\n",
       "         0.8106088 , 0.80641421, 0.80978265, 0.80472645, 0.80978265]),\n",
       "  'std_test_score': array([0.02881583, 0.0350446 , 0.02961785, 0.03755839, 0.03770408,\n",
       "         0.02947941, 0.02918427, 0.0282623 , 0.03633246, 0.03284542,\n",
       "         0.03868529, 0.03365321, 0.03293271, 0.03233945, 0.03701187,\n",
       "         0.04116264, 0.03628438, 0.0322028 , 0.03017789, 0.03413211,\n",
       "         0.03646921, 0.02917056, 0.03183087, 0.04119468, 0.03655237,\n",
       "         0.03386352, 0.03638774, 0.0359687 , 0.03477876, 0.02949519,\n",
       "         0.02632752, 0.03280945, 0.03507986, 0.03234385, 0.03293277,\n",
       "         0.02668454, 0.03526963, 0.03227969, 0.02602462, 0.03092769]),\n",
       "  'rank_test_score': array([35,  9, 20, 39, 27, 34, 18, 31, 38, 29, 21, 19, 37, 32, 23, 16, 10,\n",
       "          4, 13, 30, 40, 33, 10, 27, 24, 25, 26, 36,  8, 17, 14, 10,  2,  3,\n",
       "          1,  5, 14,  6, 21,  6], dtype=int32)},\n",
       " {'subsample': 0.74},\n",
       " 0.8123107470836436)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsample 추가 튜닝하기\n",
    "param_test4 = {\n",
    " 'subsample':[i/100.0 for i in range(40,80)],\n",
    "}\n",
    "\n",
    "xgb5 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = 0.15,\n",
    "    skip_drop = 0.33,\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=gsearch1.best_params_['max_depth'],\n",
    "    min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "    gamma=gsearch2.best_params_['gamma'],\n",
    "    subsample = gsearch3.best_params_['subsample'],\n",
    "    colsample_bytree = gsearch3.best_params_['colsample_bytree'],\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gsearch4 = GridSearchCV(estimator = xgb5, \n",
    "                        param_grid = param_test4, scoring='accuracy', n_jobs=-1, iid=False, cv=5, verbose=10)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "handled-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:  6.3min remaining:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([35.01343803, 33.06451864, 31.87412405, 35.17728953, 36.13262448,\n",
       "         33.11790128, 35.83645515, 34.51584997, 29.00652962]),\n",
       "  'std_fit_time': array([0.96853782, 4.27064355, 3.26566248, 0.49522371, 1.71216269,\n",
       "         1.92138669, 1.17391731, 0.48228308, 8.25062032]),\n",
       "  'mean_score_time': array([0.01449032, 0.0130919 , 0.01246939, 0.0113853 , 0.01552682,\n",
       "         0.01442266, 0.03317804, 0.01397858, 0.01491027]),\n",
       "  'std_score_time': array([0.00787979, 0.00576964, 0.00328633, 0.00646876, 0.01004251,\n",
       "         0.00922464, 0.02024737, 0.00617497, 0.00756098]),\n",
       "  'param_rate_drop': masked_array(data=[0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_skip_drop': masked_array(data=[0.1, 0.3, 0.5, 0.1, 0.3, 0.5, 0.1, 0.3, 0.5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'rate_drop': 0.1, 'skip_drop': 0.1},\n",
       "   {'rate_drop': 0.1, 'skip_drop': 0.3},\n",
       "   {'rate_drop': 0.1, 'skip_drop': 0.5},\n",
       "   {'rate_drop': 0.3, 'skip_drop': 0.1},\n",
       "   {'rate_drop': 0.3, 'skip_drop': 0.3},\n",
       "   {'rate_drop': 0.3, 'skip_drop': 0.5},\n",
       "   {'rate_drop': 0.5, 'skip_drop': 0.1},\n",
       "   {'rate_drop': 0.5, 'skip_drop': 0.3},\n",
       "   {'rate_drop': 0.5, 'skip_drop': 0.5}],\n",
       "  'split0_test_score': array([0.74369748, 0.78151261, 0.76890756, 0.74369748, 0.7605042 ,\n",
       "         0.75630252, 0.74789916, 0.76470588, 0.7605042 ]),\n",
       "  'split1_test_score': array([0.77731092, 0.78571429, 0.79831933, 0.76470588, 0.78571429,\n",
       "         0.78571429, 0.77310924, 0.78571429, 0.78151261]),\n",
       "  'split2_test_score': array([0.8487395 , 0.84033613, 0.86134454, 0.85714286, 0.8487395 ,\n",
       "         0.85294118, 0.85714286, 0.84033613, 0.85714286]),\n",
       "  'split3_test_score': array([0.83122363, 0.80590717, 0.8185654 , 0.81012658, 0.81012658,\n",
       "         0.82278481, 0.83544304, 0.80590717, 0.82700422]),\n",
       "  'split4_test_score': array([0.8185654 , 0.79746835, 0.80590717, 0.8185654 , 0.81012658,\n",
       "         0.79746835, 0.82700422, 0.8185654 , 0.79746835]),\n",
       "  'mean_test_score': array([0.80390739, 0.80218771, 0.8106088 , 0.79884764, 0.80304223,\n",
       "         0.80304223, 0.8081197 , 0.80304578, 0.80472645]),\n",
       "  'std_test_score': array([0.03821925, 0.02092961, 0.03016472, 0.0403027 , 0.02932016,\n",
       "         0.03284996, 0.04088693, 0.02611492, 0.03403219]),\n",
       "  'rank_test_score': array([4, 8, 1, 9, 6, 6, 2, 5, 3], dtype=int32)},\n",
       " {'rate_drop': 0.1, 'skip_drop': 0.5},\n",
       " 0.8106088004822183)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rate_drop, skip_drop 튜닝\n",
    "param_test5 = {\n",
    " 'rate_drop':[0.1, 0.3, 0.5],\n",
    " 'skip_drop':[0.1, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "xgb6 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = 0.15,\n",
    "    skip_drop = 0.33,\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=gsearch1.best_params_['max_depth'],\n",
    "    min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "    gamma=gsearch2.best_params_['gamma'],\n",
    "    subsample = gsearch4.best_params_['subsample'],\n",
    "    colsample_bytree = gsearch3.best_params_['colsample_bytree'],\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gsearch5 = GridSearchCV(estimator = xgb6, \n",
    "                        param_grid = param_test5, scoring='accuracy', n_jobs=-1, iid=False, cv=5, verbose=10)\n",
    "gsearch5.fit(train[predictors],train[target])\n",
    "gsearch5.cv_results_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "pediatric-brook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.4, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=5, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=60, n_jobs=-1, nthread=-1,\n",
      "              num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=1, seed=2021, skip_drop=0.5, subsample=0.74,\n",
      "              tree_method=None, ...)\n",
      "\n",
      "Model Report\n",
      "Training Accuracy : 0.8274\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate 감소\n",
    "xgb7 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = gsearch5.best_params_['rate_drop'],\n",
    "    skip_drop = gsearch5.best_params_['skip_drop'],\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=gsearch1.best_params_['max_depth'],\n",
    "    min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "    gamma=gsearch2.best_params_['gamma'],\n",
    "    subsample = gsearch4.best_params_['subsample'],\n",
    "    colsample_bytree = gsearch3.best_params_['colsample_bytree'],\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "modelfit(xgb7, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-religion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "patent-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scale',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type...\n",
       "                                               tree_method=None, ...)],\n",
       "                         'clf__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
       "                         'scale': [MinMaxScaler(copy=True,\n",
       "                                                feature_range=(0, 1)),\n",
       "                                   StandardScaler(copy=True, with_mean=True,\n",
       "                                                  with_std=True),\n",
       "                                   RobustScaler(copy=True,\n",
       "                                                quantile_range=(25.0, 75.0),\n",
       "                                                with_centering=True,\n",
       "                                                with_scaling=True)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate, scaler 테스트\n",
    "pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('clf', XGBClassifier())])\n",
    "\n",
    "xgb7 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = gsearch5.best_params_['rate_drop'],\n",
    "    skip_drop = gsearch5.best_params_['skip_drop'],\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=gsearch1.best_params_['max_depth'],\n",
    "    min_child_weight=gsearch1.best_params_['min_child_weight'],\n",
    "    gamma=gsearch2.best_params_['gamma'],\n",
    "    subsample = gsearch4.best_params_['subsample'],\n",
    "    colsample_bytree = gsearch3.best_params_['colsample_bytree'],\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid = dict(clf=[xgb7],\n",
    "                  clf__learning_rate=[0.01, 0.03, 0.05, 0.1],\n",
    "                 scale=[MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "                 )\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid,\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "listed-infrared",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8123036556394709,\n",
       " {'clf': XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=0.9, eval_metric='error',\n",
       "                gamma=0.4, gpu_id=-1, importance_type='gain',\n",
       "                interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "                max_depth=3, min_child_weight=5, missing=nan,\n",
       "                monotone_constraints='()', n_estimators=1000, n_jobs=-1,\n",
       "                nthread=-1, num_parallel_tree=1, objective='binary:logistic',\n",
       "                random_state=2021, rate_drop=0.1, reg_alpha=0, reg_lambda=1,\n",
       "                scale_pos_weight=1, seed=2021, skip_drop=0.5, subsample=0.74,\n",
       "                tree_method='exact', ...),\n",
       "  'clf__learning_rate': 0.1,\n",
       "  'scale': StandardScaler(copy=True, with_mean=True, with_std=True)})"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-serum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "parental-world",
   "metadata": {},
   "source": [
    "# 변수 스케일링 및 분포 변환\n",
    "\n",
    "모델의 성능을 높이기 위해 변수의 분포를 변환시키나 스케일을 조정하는 등 전처리 과정을 반복적으로 진행할 필요가 있다. 모델 특성 및 데이터 특성 등에 따라 적합한 전처리 과정이 다르므로 여러 번의 시도를 통해 모델의 성능을 올릴 필요가 있다.\n",
    "\n",
    "- (스케일링) Standardization, Mean Normalizatoin, MinMax Scaling\n",
    "- (분포변환) Log, Sqrt, Sqaure for distribution transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-glory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "underlying-cloud",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-magnet",
   "metadata": {},
   "source": [
    "### RandomForest GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "guided-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rf(X_train, y_train, X_test, y_test, p, cv_):\n",
    "    params = p\n",
    "    rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=cv_, n_jobs=-1, verbose=3,\n",
    "                          scoring='accuracy')\n",
    "    grid_cv.fit(X_train, y_train)\n",
    "\n",
    "    pred = grid_cv.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print(accuracy)\n",
    "    return grid_cv\n",
    "\n",
    "def show_feature_importances(grid_cv):\n",
    "    ftr_importances_values = grid_cv.best_estimator_.feature_importances_\n",
    "    ftr_importances_values = pd.Series(ftr_importances_values, index=X_train.columns)\n",
    "\n",
    "    ftr_top20 = ftr_importances_values.sort_values(ascending=False)[:20]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('feature importance top 20')\n",
    "    sns.barplot(x=ftr_top20, y=ftr_top20.index)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "brutal-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835016835016835\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[50, 100, 150],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth':[8, 12, 16],\n",
    "    'min_samples_leaf':[4, 8, 12],\n",
    "    'min_samples_split':[4, 8, 12]\n",
    "}\n",
    "\n",
    "X_rf_grid = test_rf(X_train, y_train, X_test, y_test,\n",
    "                      params, StratifiedKFold(n_splits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "inappropriate-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'gini',\n",
       "  'max_depth': 12,\n",
       "  'min_samples_leaf': 4,\n",
       "  'min_samples_split': 4,\n",
       "  'n_estimators': 150},\n",
       " 0.808931673935397)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rf_grid.best_params_, X_rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "controversial-source",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_feature_importances(X_rf_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-accounting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "taken-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19895018 0.23881906 0.25569496 0.07129039 0.02716665 0.01943401\n",
      " 0.01516192 0.05276086 0.02846111 0.02285385 0.02240358 0.02197045\n",
      " 0.02503298]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>startprice</td>\n",
       "      <td>0.255695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BuyItNow</td>\n",
       "      <td>0.238819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>0.198950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>productSeries_imputed</td>\n",
       "      <td>0.071290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>upperCaseDescription_rate</td>\n",
       "      <td>0.052761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>startprice_point9</td>\n",
       "      <td>0.028461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product_isNote_imputed</td>\n",
       "      <td>0.027167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>carrier_none_1</td>\n",
       "      <td>0.025033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>color_sentiment_0</td>\n",
       "      <td>0.022854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>color_sentiment_1</td>\n",
       "      <td>0.022404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>carrier_none_0</td>\n",
       "      <td>0.021970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hasDescription</td>\n",
       "      <td>0.019434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>charCountDescriptionBins</td>\n",
       "      <td>0.015162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                features_name  importance\n",
       "2                  startprice    0.255695\n",
       "1                    BuyItNow    0.238819\n",
       "0                       index    0.198950\n",
       "3       productSeries_imputed    0.071290\n",
       "7   upperCaseDescription_rate    0.052761\n",
       "8           startprice_point9    0.028461\n",
       "4      product_isNote_imputed    0.027167\n",
       "12             carrier_none_1    0.025033\n",
       "9           color_sentiment_0    0.022854\n",
       "10          color_sentiment_1    0.022404\n",
       "11             carrier_none_0    0.021970\n",
       "5              hasDescription    0.019434\n",
       "6    charCountDescriptionBins    0.015162"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc_model = ExtraTreesClassifier()\n",
    "etc_model.fit(X, y)\n",
    "\n",
    "print(etc_model.feature_importances_)\n",
    "feature_list = pd.concat([pd.Series(X.columns), pd.Series(etc_model.feature_importances_)], axis=1)\n",
    "feature_list.columns = ['features_name', 'importance']\n",
    "feature_list.sort_values(\"importance\", ascending =False)[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-light",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "negative-biodiversity",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "falling-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 5\n",
      "Selected features: Index(['BuyItNow', 'upperCaseDescription_rate', 'color_sentiment_0',\n",
      "       'carrier_none_0', 'carrier_none_1'],\n",
      "      dtype='object')\n",
      "Feature Ranking: [9 1 8 6 7 5 2 1 3 1 4 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "print(f\"Selected features: {X.columns[fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fuzzy-spectacular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 5\n",
      "Selected features: Index(['index', 'BuyItNow', 'startprice', 'productSeries_imputed',\n",
      "       'upperCaseDescription_rate'],\n",
      "      dtype='object')\n",
      "Feature Ranking: [1 1 1 1 2 8 9 1 5 6 4 7 3]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "print(f\"Num Features: {fit.n_features_}\")\n",
    "print(f\"Selected features: {X.columns[fit.support_]}\")\n",
    "print(f\"Feature Ranking: {fit.ranking_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exciting-proceeding",
   "metadata": {},
   "source": [
    "# Sequential Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "circular-yemen",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/envs/AI_dev/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    1.2s finished\n",
      "\n",
      "[2021-02-24 20:48:15] Features: 12/10 -- score: -0.48937012542529057[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.7s finished\n",
      "\n",
      "[2021-02-24 20:48:15] Features: 11/10 -- score: -0.4888918701890888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.6s finished\n",
      "\n",
      "[2021-02-24 20:48:16] Features: 10/10 -- score: -0.48904265503760075"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(clone_estimator=True, cv=5,\n",
       "                          estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                       dual=False,\n",
       "                                                       fit_intercept=True,\n",
       "                                                       intercept_scaling=1,\n",
       "                                                       l1_ratio=None,\n",
       "                                                       max_iter=100,\n",
       "                                                       multi_class='auto',\n",
       "                                                       n_jobs=None,\n",
       "                                                       penalty='l2',\n",
       "                                                       random_state=None,\n",
       "                                                       solver='lbfgs',\n",
       "                                                       tol=0.0001, verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                          fixed_features=None, floating=False, forward=False,\n",
       "                          k_features=10, n_jobs=-1, pre_dispatch='2*n_jobs',\n",
       "                          scoring='neg_log_loss', verbose=2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "selector = SequentialFeatureSelector(LogisticRegression(), scoring='neg_log_loss', \n",
    "                                     verbose=2, k_features=10, forward=False, n_jobs=-1)\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "superb-scotland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('index',\n",
       " 'BuyItNow',\n",
       " 'startprice',\n",
       " 'productSeries_imputed',\n",
       " 'product_isNote_imputed',\n",
       " 'hasDescription',\n",
       " 'startprice_point9',\n",
       " 'color_sentiment_1',\n",
       " 'carrier_none_0',\n",
       " 'carrier_none_1')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-yeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-version",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "boolean-container",
   "metadata": {},
   "source": [
    "### Local Outlier Factor\n",
    "- The number of neighbors considered (parameter n_neighbors) is typically set \n",
    "    - 1) greater than the minimum number of samples a cluster has to contain, so that other samples can be local outliers relative to this cluster\n",
    "    - 2) smaller than the maximum number of close by samples that can potentially be local outliers. \n",
    "- In practice, such informations are generally not available, and taking n_neighbors=20 appears to work well in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "swedish-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neighbors = np.linspace(1, 100, num=20).astype(int)\n",
    "test_contams = np.linspace(0.01, 0.2, num=20)\n",
    "best_params, best_acc, X2, y2 = 0, 0, 0, 0\n",
    "\n",
    "def tune_lof_by_model(model, df, scaler=None, poly=None, dim_reduction=None):\n",
    "    best_params, best_acc, X2, y2 = 0, 0, 0, 0\n",
    "    for i, tn in enumerate(test_neighbors):\n",
    "        print(i, end='/')\n",
    "        for j, tc in enumerate(test_contams):\n",
    "            \n",
    "            clf = LocalOutlierFactor(n_neighbors=tn, contamination=tc)\n",
    "            y_pred = clf.fit_predict(df.drop('sold', axis=1))\n",
    "            lof_outlier_idx = pd.Series(y_pred)[pd.Series(y_pred)==-1].index\n",
    "            df_lof2 = df.drop(lof_outlier_idx)\n",
    "            \n",
    "            X2 = df_lof2.drop('sold', axis=1)\n",
    "            y2 = df_lof2.sold\n",
    "            X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y2,\n",
    "                                                                    random_state=11)\n",
    "            \n",
    "            if scaler:\n",
    "                X2_train = scaler.fit_transform(X2_train)\n",
    "                X2_test = scaler.transform(X2_test)\n",
    "                \n",
    "            if poly:\n",
    "                X2_train = poly.fit_transform(X2_train)\n",
    "                X2_test = poly.transform(X2_test)\n",
    "            \n",
    "            if dim_reduction:\n",
    "                X2_train = dim_reduction.fit_transform(X2_train)\n",
    "                X2_test = dim_reduction.transform(X2_test)\n",
    "            \n",
    "            mod = model\n",
    "            mod.fit(X2_train, y2_train)\n",
    "            mod_acc = accuracy_score(y2_test, mod.predict(X2_test))\n",
    "            if best_acc < mod_acc:\n",
    "                best_acc = mod_acc\n",
    "                best_params = (tn, tc)\n",
    "                X2 = X2\n",
    "                y2 = y2\n",
    "    return best_params, best_acc, X2, y2\n",
    "        #print(accuracy_score(y2_test, lr.predict(X2_test)))\n",
    "        #print(test_ensemble(X2_train, y2_train, X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-arbor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "identical-example",
   "metadata": {},
   "source": [
    "### RandomForest Best Model\n",
    "```python\n",
    "LocalOutlierFactor(n_neighbors=10, contamination=0.06999999999999999)\n",
    "```\n",
    "\n",
    "> final test acc = 0.866 (before LOF: Grid Best Score 0.809)\n",
    "\n",
    "```python\n",
    "rf_best = RandomForestClassifier(random_state=0, n_jobs=-1,\n",
    "                                criterion='gini', max_depth=12,\n",
    "                                min_samples_leaf=4, min_samples_split=4,\n",
    "                                n_estimators=150)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "catholic-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/20/21/22/23/24/25/26/27/28/29/30/31/32/33/34/35/36/37/38/39/40/41/42/43/44/45/46/47/48/49/50/51/52/53/54/55/56/57/58/59/60/61/62/63/64/65/66/67/68/69/70/71/72/73/74/75/76/77/78/79/80/81/82/83/84/85/86/87/88/89/90/91/92/93/94/95/96/97/98/99/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10, 0.06999999999999999), 0.8664259927797834)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best = RandomForestClassifier(random_state=0, n_jobs=-1,\n",
    "                                criterion='gini', max_depth=12,\n",
    "                                min_samples_leaf=4, min_samples_split=4,\n",
    "                                n_estimators=150)\n",
    "rf_lof_tune = tune_lof_by_model(rf_best, df)\n",
    "rf_lof_tune[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "latest-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lof_rf = rf_lof_tune[2]\n",
    "y_lof_rf = rf_lof_tune[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-secret",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "interested-objective",
   "metadata": {},
   "source": [
    "### Light GBM Best Model\n",
    "- Grid Best Score (accuracy, before LOF) = 0.815 (GridCV, StratifiedKFold(n_split=5))\n",
    "\n",
    "```python\n",
    "LocalOutlierFactor(n_neighbors=79, contamination=0.05)\n",
    "```\n",
    "\n",
    "> Final Test Acc. = 0.843\n",
    "\n",
    "```python\n",
    "{'classifier': LGBMClassifier(application='binary', boosting_type='gbdt',\n",
    "               categorical_feature=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12],\n",
    "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
    "               learning_rate=0.01, max_depth=7, metric='binary_logloss',\n",
    "               min_child_samples=15, min_child_weight=0.001, min_split_gain=0.0,\n",
    "               n_estimators=128, n_jobs=-1, num_leaves=15, objective=None,\n",
    "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "               subsample=0.25, subsample_for_bin=200000, subsample_freq=0), 'classifier__application': 'binary', 'classifier__categorical_feature': [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12], 'classifier__learning_rate': 0.01, 'classifier__max_depth': 7, 'classifier__metric': 'binary_logloss', 'classifier__min_child_samples': 15, 'classifier__n_estimators': 128, 'classifier__num_leaves': 15, 'classifier__subsample': 0.25, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
    "                   order='C'), 'poly__degree': 3, 'scale': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bearing-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((79, 0.05), 0.8439716312056738)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_best = LGBMClassifier(application='binary', boosting_type='gbdt',\n",
    "               categorical_feature=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12],\n",
    "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
    "               learning_rate=0.01, max_depth=7, metric='binary_logloss',\n",
    "               min_child_samples=15, min_child_weight=0.001, min_split_gain=0.0,\n",
    "               n_estimators=128, n_jobs=-1, num_leaves=15, objective=None,\n",
    "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "               subsample=0.25, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "lgbm_scaler = StandardScaler()\n",
    "lgbm_poly = PolynomialFeatures(degree=3)\n",
    "lgbm_lof_tune = tune_lof_by_model(lgbm_best, df,\n",
    "                                  scaler=lgbm_scaler,\n",
    "                                 poly=lgbm_poly)\n",
    "lgbm_lof_tune[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-forestry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sweet-average",
   "metadata": {},
   "source": [
    "### XGBoost Best Model\n",
    "\n",
    "```python\n",
    "LocalOutlierFactor(n_neighbors=11, contamination=0.15)\n",
    "```\n",
    "\n",
    "- Grid Best Score (accuracy, before LOF) = 0.812 (GridCV, StratifiedKFold(n_split=5))\n",
    "\n",
    "> Final Test Acc. = 0.854\n",
    "\n",
    "```python\n",
    "xgb7 = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = 0.1,\n",
    "    skip_drop = 0.5,\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.4,\n",
    "    subsample = 0.74,\n",
    "    colsample_bytree = 0.9,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "improving-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((11, 0.15000000000000002), 0.8537549407114624)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best = XGBClassifier(\n",
    "    booster='dart',\n",
    "    rate_drop = 0.1,\n",
    "    skip_drop = 0.5,\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.4,\n",
    "    subsample = 0.74,\n",
    "    colsample_bytree = 0.9,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2021,\n",
    "    eval_metric='error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_scaler = StandardScaler()\n",
    "xgb_lof_tune = tune_lof_by_model(xgb_best, df, scaler=xgb_scaler)\n",
    "xgb_lof_tune[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-found",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "marine-province",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.5\n",
      "3\n",
      "5\n",
      "0.4\n",
      "0.74\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(gsearch5.best_params_['rate_drop'], gsearch5.best_params_['skip_drop'])\n",
    "print(gsearch1.best_params_['max_depth'])\n",
    "print(gsearch1.best_params_['min_child_weight'])\n",
    "print(gsearch2.best_params_['gamma'])\n",
    "print(gsearch4.best_params_['subsample'])\n",
    "print(gsearch3.best_params_['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-aluminum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "official-gamma",
   "metadata": {},
   "source": [
    "### Support Vector Machine Best Model\n",
    "Grid Best Score (accuracy, before LOF) = 0.790 (GridCV, StratifiedKFold(n_split=5))\n",
    "\n",
    "```python\n",
    "LocalOutlierFactor(n_neighbors=37, contamination=0.1)\n",
    "```\n",
    "\n",
    "> Final Test Acc. 0.848\n",
    "\n",
    "```python\n",
    "{'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf', 'reduce_dims': PCA(copy=True, iterated_power='auto', n_components=11, random_state=None,\n",
    "    svd_solver='auto', tol=0.0, whiten=False), 'reduce_dims__n_components': 11, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
    "             with_scaling=True)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "lesbian-cannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((37, 0.09999999999999999), 0.8470149253731343)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_best = svm.SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "svm_dim_reduction = PCA(n_components=11)\n",
    "svm_scaler = RobustScaler()\n",
    "\n",
    "svc_lof_tune = tune_lof_by_model(svm_best, df, scaler=svm_scaler,\n",
    "                                dim_reduction=svm_dim_reduction)\n",
    "svc_lof_tune[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-colon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-relative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "informational-preserve",
   "metadata": {},
   "source": [
    "### Other Models?\n",
    "- Linear Regression\n",
    "- Gaussian NB\n",
    "- ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재사용할 코드\n",
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', LogisticRegression())\n",
    "                ])\n",
    "\n",
    "param_grid = [{'classifier': [LogisticRegression()],\n",
    "               'classifier__penalty': ['l1', 'l2'], \n",
    "               'classifier__C': [0.0001, 0.01, 0.1, 1, 100, 1000],\n",
    "               'scale': [MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[1, 2, 3]\n",
    "               },\n",
    "              \n",
    "              {'classifier': [LGBMClassifier()],\n",
    "              'classifier__max_depth': [3, 5, 7],\n",
    "              'classifier__num_leaves':[2**2-1, 2**4-1, 2**5-1],\n",
    "              'classifier__min_child_samples': [10, 15],\n",
    "              'classifier__subsample': [0.25, 0.5, 0.75, 1],\n",
    "             'classifier__learning_rate':[0.001, 0.005, 0.01],\n",
    "             'classifier__n_estimators':[32, 64, 128],\n",
    "               'classifier__application':['binary'],\n",
    "               'classifier__metric':['binary_logloss'],\n",
    "               'classifier__categorical_feature':[[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12]],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "              \n",
    "             ] # min_samples_split: The minimum number of samples required to split an internal node       \n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-member",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-puzzle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "european-frequency",
   "metadata": {},
   "source": [
    "### GridCV for LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grid(model, X_train, y_train, X_test, y_test, p):\n",
    "    params = p\n",
    "    model = model #RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    grid_cv = GridSearchCV(model, param_grid=params,\n",
    "                           cv=StratifiedKFold(n_splits=5),\n",
    "                           n_jobs=-1)\n",
    "    grid_cv.fit(X_train, y_train)\n",
    "    pred = grid_cv.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print(accuracy)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_p = {\"C\":np.logspace(-3, 3, 30),\n",
    "             \"penalty\":[\"l1\",\"l2\"],\n",
    "           \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "           \"tol\":np.logspace(-6, 1, 30),\n",
    "           \"multi_class\":['auto', 'ovr', 'multinomial']\n",
    "           }\n",
    "lr = LogisticRegression(multi_class='auto', random_state=0, n_jobs=-1)\n",
    "logreg_grid = test_grid(lr, X1_train, y1_train, X1_test, y1_test, logreg_p)\n",
    "logreg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_p = {\"C\":np.logspace(-3, 3, 30),\n",
    "             \"penalty\":[\"l1\",\"l2\"],\n",
    "           \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "           \"tol\":np.logspace(-6, 1, 30),\n",
    "           \"multi_class\":['auto', 'ovr', 'multinomial']\n",
    "           }\n",
    "lr = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=11)\n",
    "\n",
    "logreg_grid2 = test_grid(lr, X2_train, y2_train, X2_test, y2_test, logreg_p)\n",
    "logreg_grid2.best_params_, logreg_grid2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-robert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-director",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-transaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-thinking",
   "metadata": {},
   "source": [
    "### SVM GridSearch\n",
    "- [서포트 벡터 머신(SVM)의 사용자로서 꼭 알아야할 것들 - 매개변수 C와 gamma](https://bskyvision.com/163)\n",
    "    - [SVM model selection – how to adjust all these knobs pt. 1](https://tomaszkacmajor.pl/index.php/2016/04/24/svm-model-selection/)\n",
    "    - [SVM model selection – how to adjust all these knobs pt. 2](https://tomaszkacmajor.pl/index.php/2016/05/01/svm-model-selection2/)\n",
    "    - [Data preprocessing for SVM classifier](https://tomaszkacmajor.pl/index.php/2016/04/24/data-preprocessing/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-leather",
   "metadata": {},
   "source": [
    "### Light GBM\n",
    "설명 및 사용법 https://greeksharifa.github.io/machine_learning/2019/12/09/Light-GBM/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-essay",
   "metadata": {},
   "source": [
    "# Locally Linear Embedding\n",
    "출처: https://excelsior-cjh.tistory.com/168?category=918734 [EXCELSIOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=2, random_state=42, eigen_solver='dense')\n",
    "lle.fit(X1)\n",
    "X1_reduced = lle.transform(X1)\n",
    "plt.title(\"d\", fontsize=14)\n",
    "plt.scatter(X1_reduced[:, 0], X1_reduced[:, 1], c=y1, cmap=plt.cm.hot)\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18)\n",
    "plt.axis([-0.065, 0.055, -0.1, 0.12])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-navigation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "attractive-judgment",
   "metadata": {},
   "source": [
    "### StackingClassifier\n",
    "https://www.kaggle.com/kabirnagpal/feature-selection-and-stacking-f1-score-99\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html\n",
    "\n",
    "```python\n",
    "x_train, x_test, y_train, y_test =\\\n",
    "  train_test_split(cancer.data, cancer.target,\n",
    "                   random_state=0, test_size=0.3, stratify=cancer.target)\n",
    "```\n",
    "- train_test_split, `stratify` 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.metrics import *\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(kernel=\"rbf\"),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianNB(),\n",
    "    RidgeClassifier(),\n",
    "    LogisticRegression(max_iter=200)\n",
    "]\n",
    "def f_score(X_train, X_test, y_train, y_test):\n",
    "    for clf in classifiers:\n",
    "        s = time.time()\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        f = f1_score(y_true=y_test,y_pred=y_pred,average=\"macro\")\n",
    "        e = time.time()\n",
    "        print(f\"Score: {round(f,3)} \\t Time(in secs): {round(e-s,3)} \\t Classifier: {clf.__class__.__name__}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score(X2_train, X2_test, y2_train, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "#        ('RFC' ,RandomForestClassifier(n_estimators=500, random_state = 42)),\n",
    "#        ('KNC', KNeighborsClassifier(5)),\n",
    "#        ('DTC', DecisionTreeClassifier()),\n",
    "#        ('SVC', SVC(kernel=\"rbf\")),\n",
    "        ('GNB', GaussianNB()),\n",
    "        ('RC',  RidgeClassifier()),\n",
    "        ('LR', LogisticRegression(max_iter=200))\n",
    "]\n",
    "\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, \n",
    "    final_estimator=GradientBoostingClassifier()\n",
    ")\n",
    "\n",
    "s = time.time()\n",
    "clf.fit(X2_train,y2_train)\n",
    "y_pred = clf.predict(X2_test)\n",
    "e = time.time()\n",
    "print(f\"time consumed: {round(e-s,3)}\")\n",
    "print(accuracy_score(y2_test, y_pred))\n",
    "print(f1_score(y_true=y2_test,y_pred=y_pred,average=\"macro\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-congo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "integral-presence",
   "metadata": {},
   "source": [
    "# error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_df(grid_cv_fit, X, y):\n",
    "    \n",
    "    X_pred = pd.DataFrame(grid_cv_fit.predict(X),\n",
    "                          columns=['sold_pred'])\n",
    "    X_pred_proba = pd.DataFrame(grid_cv_fit.predict_proba(X),\n",
    "                                columns=['sold0_proba', 'sold1_proba'])\n",
    "    y = pd.DataFrame(y, columns=['sold'])\n",
    "    \n",
    "    res_df = pd.concat([X, y, X_pred, X_pred_proba], axis=1)\n",
    "    res_df['wrong_pred'] = res_df['sold'] != res_df['sold_pred']\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-measure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-banana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
