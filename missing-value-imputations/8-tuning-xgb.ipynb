{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greatest-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import svm\n",
    "from sklearn. neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "# from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.stats import expon, reciprocal\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "#from lightgbm import LGBMClassifier\n",
    "from missingpy import MissForest\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/galaxy_final.csv', index_col=0)\n",
    "X = df.drop('sold', axis=1)\n",
    "y = df.sold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11,\n",
    "                                                       stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-might",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "irish-passion",
   "metadata": {},
   "source": [
    "# XGBoost Tuning\n",
    "- https://www.kaggle.com/lifesailor/xgboost\n",
    "- https://brunch.co.kr/@snobberys/137\n",
    "- https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "\n",
    "General Parameter\n",
    "- booster: tree 기반 모델 / 선형 모델\n",
    "    - https://xzz201920.medium.com/xgbosst-booster-gbtree-v-s-dart-v-s-gblinear-82d8fcbb07d2\n",
    "    - skip_drop(default = 0, range [0, 1]) is the probability of skipping dropout. It has a higher priority than other DART parameters.\n",
    "        - If skip_drop = 1, the dropout procedure would be skipped and dart is the same as gbtree.\n",
    "    - If skip_drop≠0, rate_drop (default = 0, range [0, 1]) will drop a fraction of the trees before the model update in every iteration.\n",
    "        - dropout makes dart between gbtree and random forest: “If no tree is dropped, dart is the same as (gbtree); if all the trees are dropped, dart is no different than random forest.”\n",
    "- silent: 메세지 조절\n",
    "- nthread: 병렬 처리 조절\n",
    "\n",
    "Boost Parameter\n",
    "- eta: Learning rate(일반적으로 0.01 - 0.2)\n",
    "- min_child_weight: min_child_weight를 기준으로 추가 분기 결정(크면 Underfitting)\n",
    "- max_depth: Tree 깊이 수\n",
    "- max_leaf_node: 하나의 트리에서 node 개수\n",
    "- gamma: split 하기 위한 최소의 loss 감소 정의\n",
    "- subsample: 데이터 중 샘플링(0.5 - 1)\n",
    "- colsample_bytree: column 중 sampling(0.5 - 1)\n",
    "- colsample_bylevel: 각 level마다 샘플링 비율\n",
    "- lambda: L2 nrom\n",
    "- alpha: L1 norm\n",
    "- scale_pos_weight: positive, negative weight 지정\n",
    "- 기타 등\n",
    "\n",
    "Learning Task Parameter\n",
    "- object: 목적함수 종류\n",
    "    - binary:logistic(이진 분류)\n",
    "    - multi:softmax(다중 분류)\n",
    "    - multi-softprob(다중 확률)\n",
    "- eval_metric: 평가 지표\n",
    "    - rmse – root mean square error\n",
    "    - mae – mean absolute error\n",
    "    - logloss – negative log-likelihood\n",
    "    - error – Binary classification error rate (0.5 threshold)\n",
    "    - merror – Multiclass classification error rate\n",
    "    - mlogloss – Multiclass logloss\n",
    "    - auc: Area under the curve\n",
    "seed\n",
    "\n",
    "### Overview\n",
    "- high learning rate(0.05 - 0.3)를 선택하고 이 학습률에 맞는 tree 개수를 선정한다.\n",
    "- tree-specific parameter를 수정한다.\n",
    "- max_depth, min_child_weight, gamma, subsample, colsample_bytree\n",
    "- regularization parameter를 수정한다.\n",
    "- 학습률을 낮추고 다시 반복한다.\n",
    "\n",
    "### Initialization\n",
    "초기값은 다음과 같이 선정한다.\n",
    "- max_depth = 5: 보통 4-6 를 시작점으로 한다.\n",
    "- min_child_weight = 1 : 향후에 튜닝할 것이다.\n",
    "- gamma = 0 : 0.1 - 0.2로 시작해도 된다. 그런데 어짜피 튜닝할 것이다.\n",
    "- subsample, colsample_bytree = 0.8 : 보통 0.5 - 0.9로 시작한다.\n",
    "- scale_pos_weight = 1: Because of high class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-union",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "checked-softball",
   "metadata": {},
   "source": [
    "### 1-1. Scaler + PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fuzzy-signature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8047193560968692\n"
     ]
    }
   ],
   "source": [
    "pipe1_1 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_1 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "             ] \n",
    "grid1_1 = GridSearchCV(pipe1_1, param_grid1_1, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_1.fit(X_train, y_train)\n",
    "print(grid1_1.best_params_)\n",
    "print(grid1_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-bruce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-signature",
   "metadata": {},
   "source": [
    "### 1-2. Scaler Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "everyday-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'scale': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "0.7971492394426125\n"
     ]
    }
   ],
   "source": [
    "pipe1_2 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "#                 ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_2 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "#                'poly':[PolynomialFeatures()],\n",
    "#                'poly__degree':[1, 2, 3]\n",
    "              }\n",
    "             ] \n",
    "grid1_2 = GridSearchCV(pipe, param_grid1_2, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_2.fit(X_train, y_train)\n",
    "print(grid1_2.best_params_)\n",
    "print(grid1_2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-chosen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tired-crisis",
   "metadata": {},
   "source": [
    "### 1-3. Scale -> Poly -> ReduceDim\n",
    "\n",
    "- PCA & LDA\n",
    "    - https://huidea.tistory.com/126\n",
    "- LDA\n",
    "    - https://yamalab.tistory.com/41\n",
    "    - http://www.datamarket.kr/xe/board_oFxn34/26649\n",
    "- TSNE\n",
    "    - https://agiantmind.tistory.com/215\n",
    "    - https://lovit.github.io/nlp/representation/2018/09/28/tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bright-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 64.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=1, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 1, 'reduce_dims': PCA(copy=True, iterated_power='auto', n_components=9, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'reduce_dims__n_components': 9, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.7887281494876431\n"
     ]
    }
   ],
   "source": [
    "pipe1_3 = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                 ('poly', PolynomialFeatures()),\n",
    "                ('reduce_dims', PCA()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid1_3 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':[5],\n",
    "               'classifier__min_child_weight':[1],\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree': [1, 2, 3],\n",
    "               'reduce_dims' : [PCA(), LDA(), TSNE()],\n",
    "               'reduce_dims__n_components' : [5, 7, 9, 11]\n",
    "              }\n",
    "             ] \n",
    "grid1_3 = GridSearchCV(pipe1_3, param_grid1_3, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid1_3.fit(X_train, y_train)\n",
    "print(grid1_3.best_params_)\n",
    "print(grid1_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-stationery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-darwin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "center-steal",
   "metadata": {},
   "source": [
    "### Scaler + Poly > Scaler Only > Scaler + Poly + DimReduction\n",
    "- 0.805 > 0.797 > 0.789\n",
    "\n",
    "### max_depth, min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constitutional-minister",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8106229833705635\n"
     ]
    }
   ],
   "source": [
    "#max_depth와 min_child_weight를 튜닝한다.\n",
    "\n",
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('classifier', XGBClassifier())\n",
    "                ])\n",
    "\n",
    "param_grid2 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth':range(3,10,3),\n",
    "               'classifier__min_child_weight':range(1,6,2),\n",
    "               'classifier__gamma':[0],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid2 = GridSearchCV(pipe, param_grid2, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid2.fit(X_train, y_train)\n",
    "print(grid2.best_params_)\n",
    "print(grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-pixel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fancy-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 11.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.8, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.8, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.8, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8106229833705635\n"
     ]
    }
   ],
   "source": [
    "# Gamma를 튜닝한다.\n",
    "param_grid3 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[i/10.0 for i in range(0,10)],\n",
    "               'classifier__subsample':[0.8],\n",
    "               'classifier__colsample_bytree':[0.8],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid3 = GridSearchCV(pipe, param_grid3, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid3.fit(X_train, y_train)\n",
    "print(grid3.best_params_)\n",
    "print(grid3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-oracle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "published-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8156791830656314\n"
     ]
    }
   ],
   "source": [
    "# subsample and colsample_bytree를 튜닝한다.\n",
    "param_grid4 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid4 = GridSearchCV(pipe, param_grid4, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid4.fit(X_train, y_train)\n",
    "print(grid4.best_params_)\n",
    "print(grid4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-rocket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "insured-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': XGBClassifier(base_score=None, booster='dart', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9, eval_metric='error',\n",
      "              gamma=0.0, gpu_id=None, importance_type='gain',\n",
      "              interaction_constraints=None, learning_rate=0.1,\n",
      "              max_delta_step=None, max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=1000, n_jobs=-1,\n",
      "              nthread=-1, num_parallel_tree=None, objective='binary:logistic',\n",
      "              random_state=None, rate_drop=0.15, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=1, seed=2021, skip_drop=0.33,\n",
      "              subsample=0.7, tree_method=None, ...), 'classifier__booster': 'dart', 'classifier__colsample_bytree': 0.9, 'classifier__eval_metric': 'error', 'classifier__gamma': 0.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__min_child_weight': 1, 'classifier__n_estimators': 1000, 'classifier__n_jobs': -1, 'classifier__nthread': -1, 'classifier__objective': 'binary:logistic', 'classifier__rate_drop': 0.15, 'classifier__scale_pos_weight': 1, 'classifier__seed': 2021, 'classifier__skip_drop': 0.33, 'classifier__subsample': 0.7, 'poly': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 3, 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "0.8156791830656314\n"
     ]
    }
   ],
   "source": [
    "# n_estimators 튜닝\n",
    "\n",
    "param_grid5 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [0.15],\n",
    "              'classifier__skip_drop': [0.33],\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[50, 100, 300, 500, 750, 1000],\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid5 = GridSearchCV(pipe, param_grid5, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid5.fit(X_train, y_train)\n",
    "print(grid5.best_params_)\n",
    "print(grid5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-basket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.0min\n"
     ]
    }
   ],
   "source": [
    "# rate_drop, skip_drop 튜닝\n",
    "param_grid6 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': np.arange(0.1, 0.55, 0.05),\n",
    "              'classifier__skip_drop': np.arange(0.1, 0.55, 0.05),\n",
    "             'classifier__learning_rate':[0.1],\n",
    "             'classifier__n_estimators':[grid5.best_params_['classifier__n_estimators']], # 1000\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ] \n",
    "grid6 = GridSearchCV(pipe, param_grid6, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid6.fit(X_train, y_train)\n",
    "print(grid6.best_params_)\n",
    "print(grid6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-wesley",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "\n",
    "param_grid7 = [              \n",
    "              {'classifier': [XGBClassifier()],\n",
    "              'classifier__booster': ['dart'],\n",
    "              'classifier__rate_drop': [grid6.best_params_['classifier__rate_drop']],\n",
    "              'classifier__skip_drop': [grid6.best_params_['classifier__skip_drop']],\n",
    "             'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "             'classifier__n_estimators':[grid5.best_params_['classifier__n_estimators']], # 1000\n",
    "               'classifier__max_depth': [grid2.best_params_['classifier__max_depth']], # 3\n",
    "               'classifier__min_child_weight': [grid2.best_params_['classifier__min_child_weight']], # 1\n",
    "               'classifier__gamma':[grid3.best_params_['classifier__gamma']], # 0.0\n",
    "               'classifier__subsample':[grid4.best_params_['classifier__subsample']], # 0.7\n",
    "               'classifier__colsample_bytree':[grid4.best_params_['classifier__colsample_bytree']], # 0.9\n",
    "               'classifier__objective':['binary:logistic'],\n",
    "               'classifier__nthread':[-1],\n",
    "               'classifier__scale_pos_weight':[1],\n",
    "               'classifier__seed':[2021],\n",
    "               'classifier__eval_metric':['error'],\n",
    "               'classifier__n_jobs':[-1],\n",
    "               'scale':[RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[3]\n",
    "              }\n",
    "             ]\n",
    "grid7 = GridSearchCV(pipe, param_grid7, scoring = 'accuracy',\n",
    "                    cv=StratifiedKFold(n_splits=5),\n",
    "                    verbose=1, n_jobs=-1)\n",
    "grid7.fit(X_train, y_train)\n",
    "print(grid7.best_params_)\n",
    "print(grid7.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-balloon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit - early stopping rounds\n",
    "xgb_best = grid7.best_estimator_\n",
    "\n",
    "for esr in np.arange(0.1, 0.55, 0.05):\n",
    "    xgb_best.fit(X_train, y_train, early_stopping_rounds=50, eval_metric=\"accuracy\",\n",
    "                eval_set=[(X_train, y_train), (X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-elimination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-imagination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "coastal-swimming",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neighbors = np.linspace(1, 100, num=20).astype(int)\n",
    "test_contams = np.linspace(0.01, 0.2, num=20)\n",
    "best_params, best_acc, X2, y2 = 0, 0, 0, 0\n",
    "\n",
    "def tune_lof_by_model(model, df, scaler=None, poly=None, dim_reduction=None):\n",
    "    best_params, best_acc, X2, y2 = 0, 0, 0, 0\n",
    "    for i, tn in enumerate(test_neighbors):\n",
    "        print(i, end='/')\n",
    "        for j, tc in enumerate(test_contams):\n",
    "            \n",
    "            clf = LocalOutlierFactor(n_neighbors=tn, contamination=tc)\n",
    "            y_pred = clf.fit_predict(df.drop('sold', axis=1))\n",
    "            lof_outlier_idx = pd.Series(y_pred)[pd.Series(y_pred)==-1].index\n",
    "            df_lof2 = df.drop(lof_outlier_idx)\n",
    "            \n",
    "            X2 = df_lof2.drop('sold', axis=1)\n",
    "            y2 = df_lof2.sold\n",
    "            X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    shuffle=True,\n",
    "                                                                    stratify=y2,\n",
    "                                                                    random_state=11)\n",
    "            \n",
    "            if scaler:\n",
    "                X2_train = scaler.fit_transform(X2_train)\n",
    "                X2_test = scaler.transform(X2_test)\n",
    "                \n",
    "            if poly:\n",
    "                X2_train = poly.fit_transform(X2_train)\n",
    "                X2_test = poly.transform(X2_test)\n",
    "            \n",
    "            if dim_reduction:\n",
    "                X2_train = dim_reduction.fit_transform(X2_train)\n",
    "                X2_test = dim_reduction.transform(X2_test)\n",
    "            \n",
    "            mod = model\n",
    "            mod.fit(X2_train, y2_train)\n",
    "            mod_acc = accuracy_score(y2_test, mod.predict(X2_test))\n",
    "            if best_acc < mod_acc:\n",
    "                best_acc = mod_acc\n",
    "                best_params = (tn, tc)\n",
    "                X2 = X2\n",
    "                y2 = y2\n",
    "    return best_params, best_acc, X2, y2\n",
    "        #print(accuracy_score(y2_test, lr.predict(X2_test)))\n",
    "        #print(test_ensemble(X2_train, y2_train, X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best = LGBMClassifier(application='binary', boosting_type='dart',\n",
    "               categorical_feature=[0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12],\n",
    "               class_weight=None, colsample_bytree=0.8, importance_type='split',\n",
    "               learning_rate=0.03, max_depth=9, metric='binary_logloss',\n",
    "               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.0,\n",
    "               n_estimators=100, n_jobs=-1, num_leaves=16, objective='binary',\n",
    "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "               subsample=0.5, subsample_for_bin=200000, subsample_freq=0,\n",
    "                          drop_rate=0.4, skip_drop=0.4, num_iterations=1000)\n",
    "\n",
    "lgbm_scaler = MinMaxScaler()\n",
    "lgbm_poly = PolynomialFeatures(degree=3)\n",
    "lgbm_lof_tune = tune_lof_by_model(lgbm_best, df,\n",
    "                                  scaler=lgbm_scaler,\n",
    "                                 poly=lgbm_poly)\n",
    "lgbm_lof_tune[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-belgium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-prime",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-cradle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-appliance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
